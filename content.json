{"meta":{"title":"Reason's blog","subtitle":null,"description":null,"author":"reason","url":"https://reasoncai.github.io"},"pages":[],"posts":[{"title":"Docker实践系列3-使用DockerRegistry管理镜像","slug":"Docker实践系列3-使用DockerRegistry管理镜像","date":"2017-06-04T15:51:56.000Z","updated":"2017-06-04T15:54:58.000Z","comments":true,"path":"2017/06/04/Docker实践系列3-使用DockerRegistry管理镜像/","link":"","permalink":"https://reasoncai.github.io/2017/06/04/Docker实践系列3-使用DockerRegistry管理镜像/","excerpt":"","text":"Docker Hub相当于maven中央仓库 Docker Registry相当于局域网的mavan仓库（nexus） 1.使用DockerHub 注册登录docker hub 在docker hub上创建仓库 推送本地镜像到docker hub 1$ docker push cai/java 输出没有授权，需要登录 1$ docker login 2.搭建Docker Registry2.1.启动Docker Registry1$ docker run -d -p 50000:50000 -v ~/docker-registry:/tmp/registry registry -d:表示将在后台启动该容器。 -p:表示端口映射。左边的为宿主机的端口，右边的为容器内部需要暴露的端口 -v:推送的镜像文件会放在容器的/tmp/registry,这样设置能可通过宿主机访问已推送的镜像，对镜像文件备份。 还可以通过访问127.0.0.1:50000/v1/search，搜索docker registry中的镜像仓库。 2.2.重命名镜像标签由于cai/java镜像默认的注册中心为Docker Hub，我们使用docker push命令推送的目标地址实际上都是docker hub，因此cai/java镜像的完整名称应为docker.io/cai/java。如果我们打算将cai/java镜像推送至本地的docker registry，则需将镜像名称修改为127.0.0.1:5000/cai/java。 1$ docker tag fwfdfw21213e2 127.0.0.1:5000/cai/java 2.3.推送镜像1$ docker push 127.0.0.1:5000/cai/java 一般情况下，我们可将Docker Registry与Nginx集成，将它们部署在一台稳定的服务器上，通过Nginx反向代理的方式来调用Docker Registry,并将IP绑定到一个内部域名上，比如docker-registry.xxx.com。","categories":[{"name":"DOCKER","slug":"DOCKER","permalink":"https://reasoncai.github.io/categories/DOCKER/"}],"tags":[{"name":"DOCKER","slug":"DOCKER","permalink":"https://reasoncai.github.io/tags/DOCKER/"}]},{"title":"Docker实践系列2-制作镜像","slug":"Docker实践系列2-制作镜像","date":"2017-05-31T15:39:55.000Z","updated":"2017-06-04T15:56:03.000Z","comments":true,"path":"2017/05/31/Docker实践系列2-制作镜像/","link":"","permalink":"https://reasoncai.github.io/2017/05/31/Docker实践系列2-制作镜像/","excerpt":"","text":"1.手工制作Java镜像 从docker hub中获取一份centos镜像到本地，准备oracle jdk的压缩包放在宿主机的/software目录下。 启动centos容器 1$ docker run -i -t -v /software:/mnt/software centos /bin/bash -v选项，即数据卷（DataVolume），用于将宿主机上的磁盘挂载到容器中。格式为“宿主机路径:容器路径”，宿主机路径可以为相对路径，容器路径必须为绝对路径，此外，多次使用-v选项，可以同时挂载多个宿主机路径到容器中。 进入容器后，执行命令,安装JDK 1234567891011#验证是否挂载成功ll /mnt/software#解压jdk压缩包tar -zxf /mnt/software/jdk-8u91-linux-x64.tar.gz -C /opt#查看解压文件夹ll /opt#为了便于访问与升级，建立一个软连接，用于快速访问JDK跟目录ln -s /opt/jdk1.8.0_91 /opt/jdkll /opt/jdk#验证JDK是否安装成功/opt/jdk/bin/java -version 提交镜像 再打开一个终端，查看当前运行中的容器12345$ docker ps#提交容器为一个新的镜像docker commit be3dsddwewq2 cai/java#验证查看本地是否保护cai/java镜像$ docker images 验证镜像 用刚才创建的镜像启动一个容器，若容器能成功输出java版本号，则说明镜像是可用的。1$ docker run --rm cai/java /opt/jdk/bin/java -version -rm选项，表示当容器退出时可自动删除容器，也就是运行完java -version命令后，容器自动退出。当我们不想保留该容器，自动执行docker rm操作，将自己删除。 2.使用Dockerfile构建镜像2.1.Dockerfile基本结构Dockerfile实际上是一个编写Docker镜像的脚本，该脚本有一个固定的格式。我们首先创建一个空白的文本文件，文件名为Dockerfile。其实叫其他名字也可以，只是Dockerfile是默认的文件名而已。 设置基础镜像 当前构建的镜像必须继承于某个“基础镜像”,例如基于centos最新版镜像： 1FROM centos:latest FROM指令有固定的格式，即“仓库名:标签名”,若使用最新版本，则latest可以省略。 设置维护者信息 1MAINTAINER &quot;CAI&quot;&lt;403411876@qq.com&gt; 设置需要添加到容器的文件 例如我们从Oracle官网下载的JDK压缩包，可使用ADD指令将此文件添加到容器的指定目录中： 1ADD jdk-8u91-linux-x64.tar.gz /opt ADD指令的第一个参数为宿主机的来源路径（可用相对路径），第二个参数是容器的目标路径（必须为绝对路径）。ADD指令将自动解压来源路径中的压缩包，将解压后的文件复制到目标路径中。此外我们一般将Dockerfile文件与需要添加到容器的文件放在同一目录下，这样有助于编写来源路径。 还有一个与ADD指令功能类似的COPY指令，只是后者只能完成简单的复制，而没有自动解压的功能。 设置镜像制作过程中需要执行的命令 1RUN ln -s /opt/jdk1.8.0_91 /opt/jdk 如果需要执行多条命令，我们可以使用多行RUN命令，但如果将多条指令通过\\命令换行符合并成一条，这样将减少所构建的镜像的体积。原因是，在镜像中每执行一条命令，都会形成新的“镜像层”，我们需要尽可能减少镜像层，从而减少镜像体积。 设置容器启动时需要执行的命令 我们在使用docker run命令时，可在命令的最后一段添加一个容器启动时需要执行的命令，在Dockerfile中也有相对应的CMD指令 1CMD /opt/jdk/bin/java -version 如果使用docker run命令时指定了需要执行的命令，那么该命令将覆盖Dockerfile中通过CMD设置的命令。 还有一个类似的ENTRYPOINT指令，他所执行的指令不能被docker run命令所覆盖。 CMD指令要么没有，要么只有一条，CMD指令还能与ENTRYPOINT指令联合使用。 2.2.使用Dockerfile构建镜像Dockerfile内容如下：12345FROM centos:latestMAINTAINER &quot;CAI&quot;&lt;403411876@qq.com&gt;ADD jdk-8u91-linux-x64.tar.gz /optRUN ln -s /opt/jdk1.8.0_91 /opt/jdkCMD /opt/jdk/bin/java -version 使用docker build 命令读取Dockerfile文件，并构建一个镜像 1$ docker bulid -t cai/java . -t选项指定镜像的名称，并读取当前的目录(即.目录)中的Dockerfile文件。 通过docker images发现这次构建的镜像与之前手工构建的镜像所包括的仓库名与标签名完全相同，之前的都被更新为了。用以下命令修改执行的仓库名和标签名 1$ docker tag eirj313213 cai/java:1.0 Dockerfile也提供设置环境变量的指令，ENV1234567FROM centos:latestMAINTAINER &quot;CAI&quot;&lt;403411876@qq.com&gt;ADD jdk-8u91-linux-x64.tar.gz /optRUN ln -s /opt/jdk1.8.0_91 /opt/jdkENV JAVA_HOME /opt/jdkENV PATH $JAVA_HOME/bin:$PATHCMD java -version 2.3.Dockerfile的其他指令","categories":[{"name":"DOCKER","slug":"DOCKER","permalink":"https://reasoncai.github.io/categories/DOCKER/"}],"tags":[{"name":"DOCKER","slug":"DOCKER","permalink":"https://reasoncai.github.io/tags/DOCKER/"}]},{"title":"Docker实践系列1-基本命令","slug":"Docker实践系列1-基本命令","date":"2017-05-30T09:00:24.000Z","updated":"2017-06-04T15:56:39.000Z","comments":true,"path":"2017/05/30/Docker实践系列1-基本命令/","link":"","permalink":"https://reasoncai.github.io/2017/05/30/Docker实践系列1-基本命令/","excerpt":"","text":"1.如何使用Docker1.1.Docker镜像常用操作1.1.1.列出本地可用镜像1$ docker images 1.1.2.拉取镜像1$ docker pull centos 执行以上命令后，docker客户端将连接docker hub，并自动从centos镜像仓库中下载最新版本的centos镜像。下载完后可再次通过docker images命令列出镜像： REPOSITORY TAG IMAGE ID CREATED SIZE centos lastest d0e7f81ca65c 3 months ago 196.6 MB IMAGE ID:表示镜像的标识符，具备唯一性。这里看到的是一串12位的字符串，实际上它是64位完整镜像ID的缩略表达形式。 1.1.3.搜索镜像1$ docker search centos 1.1.4.删除镜像123$ docker rmi centos$ docker rmi -f centos #强制删除有容器在跑的镜像$ docker rmi -f `docker images -a -q` #一次性删除所有镜像 使用以上命令在Docker hub中搜索centos镜像。 1.1.5.导出与导入镜像使用以下命令导出centos镜像为一个tar文件（镜像包）：1$ docker save centos &gt; centos.tar 若不指定导出的tar文件路径，则导出的centos.tar文件在当前目录上。 导出的centos.tar镜像包文件可随时在另一台Docker机器上导入：1$ docker load &lt; centos.tar 当我们获取了centos镜像后，就能基于该镜像启动相应的容器。 1.2.Docker容器常用操作1.2.1.创建并启动容器使用以下命令在运行centos镜像，从而创建并启动centos容器：1$ docker run -i -t centos /bin/bash 需要注意的是该命令实际上首先从本地获取centos镜像，若本地没有，则从docker hub拉取centos镜像并放入本地，随后才根据镜像创建并启动centos容器。 -i选项：表示启动容器后，打开标准输入设备（STDIN）,可使用键盘进行输入。 -t选项：表示启动容器后，分配一个伪终端（pseudo-TTY）,将于服务器建立一个会话。 centos参数：表示需要运行的镜像名称，标准格式为centos:latest,若为latest版本，则可省略。 /bin/bash参数：表示运行容器中的bash应用程序，因为我们此时并不需要运行其他程序，只想进入到容器中。1.2.2.列出容器1$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PROTS NAMES 21e21e1j212j centos “/bin/bash” 8 hours age Up 5 seconds ekdsaf_dfds COMMAND:表示启动容器时运行的命令。 NAMES:表示容器的名称，由docker引擎自动生成，也可以在docker run命令中通过–name选项来指定。 1.2.3.进入容器使用以下命令进入运行中的容器(需指定容器ID或容器名称)：1$ docker attach 21e21e1j212j 只能进入运行中的容器，不能进入已停止的容器。此外，当打开多个终端并进入容器时，在一个终端中执行了某命令，该命令自动同步到其他终端中。例如在一个终端中执行了exit命令，将从终端中退出容器，此时其他终端也会自动退出容器。 1.2.4.执行命令使用以下命令向运行中的容器执行具体的命令(需指定容器ID或容器名称)：1$ docker exec -i -t 21e21e1j212j ls -l 1.2.5.停止容器使用以下命令停止运行中的容器(需指定容器ID或容器名称)：1$ docker stop 21e21e1j212j 使用该命令可对容器发送SIGTERM信号，将等待一段很短的时间，再对容器发送SIGKILL信号，立刻终止容器。 1.2.6.终止容器使用以下命令终止运行中的容器(需指定容器ID或容器名称)：1$ docker kill 21e21e1j212j 对容器发送SIGKILL信号，立刻终止容器 1.2.7.启动容器使用以下命令启动已停止的容器(需指定容器ID或容器名称)：1$ docker start 21e21e1j212j 1.2.8.重启容器使用以下命令重启运行中的容器(需指定容器ID或容器名称)：1$ docker restart 21e21e1j212j 该命令实际上首先执行了docker stop，再执行docker start. 1.2.9.删除容器使用以下命令删除已停止的容器(需指定容器ID或容器名称)：123$ docker rm 21e21e1j212j$ docker rm -f 21e21e1j212j #强制删除运行中的容器或 $ docker rm -f `docker ps -a -q` #一次性删除所有容器 1.2.10.导出与导入容器使用以下命令导出容器为一个tar文件（容器包）：1$ docker export 21e21e1j212j &gt; centos.tar 导出的centos.tar容器包可随时在另一个docker机器上导入为镜像，命令为：1$ docker import centos.tar cai/centos:latest 需要注意的是，我们之前用docker load 命令（从镜像包中导入镜像）与现在用docker import(从容器包中导入镜像)都可以导入镜像，区别是容器包不包含任何历史记录，相当于容器的当前快照，镜像包则包含所有的历史记录，因此镜像包的体积较大。 1.3.Docker命令汇总1$ docker help","categories":[{"name":"DOCKER","slug":"DOCKER","permalink":"https://reasoncai.github.io/categories/DOCKER/"}],"tags":[{"name":"DOCKER","slug":"DOCKER","permalink":"https://reasoncai.github.io/tags/DOCKER/"}]},{"title":"一种简单的微服务架构拆分方案","slug":"一种简单的微服务架构拆分方案","date":"2017-05-28T15:31:48.000Z","updated":"2017-05-28T15:47:54.000Z","comments":true,"path":"2017/05/28/一种简单的微服务架构拆分方案/","link":"","permalink":"https://reasoncai.github.io/2017/05/28/一种简单的微服务架构拆分方案/","excerpt":"","text":"架构拆分 拆分：按行分层，按列分业务 在这个微服务体系中，所有的服务被划分为了三个层次： 基础设施层：为所有业务提供基础设施，包括服务注册、数据库和NoSQL、对象存储、消息队列等基础设施服务，这一层通常是由成熟组件、第三方服务组成。 业务服务层：业务微服务，根据业务领域每个子域单独一个微服务，分而治之。 接入层：直接对外提供服务，例如网站、API接口等。接入层不包含复杂的业务逻辑，只做呈现和转换。 项目中我们主要关注业务服务层和接入层，对于没有足够运维力量的团队，基础设施使用云服务是省事省力的选择。 对于业务服务层和接入层建立之初便订立了如下原则： 业务逻辑层内所有服务完全对等，可相互调用 业务逻辑层所有服务必须是无状态的 接入层所有服务可调用业务逻辑层所有服务，但接入层内部同层服务之间不可调用 接入层不能包含业务逻辑代码 所有微服务必须运行在Docker容器里 业务逻辑层主要使用Java（Spring cloud），接入层主要使用Node。","categories":[{"name":"架构","slug":"架构","permalink":"https://reasoncai.github.io/categories/架构/"}],"tags":[{"name":"SPRING CLOUD","slug":"SPRING-CLOUD","permalink":"https://reasoncai.github.io/tags/SPRING-CLOUD/"}]},{"title":"Java方法参数传递","slug":"Java方法参数传递","date":"2017-05-28T15:06:25.000Z","updated":"2017-05-28T15:51:02.000Z","comments":true,"path":"2017/05/28/Java方法参数传递/","link":"","permalink":"https://reasoncai.github.io/2017/05/28/Java方法参数传递/","excerpt":"","text":"1.基础概念 值传递表示方法接收的是调用者提供的值。 引用传递表示方法接收的是调用者提供的变量地址 Java总是采用值传递的方式。不像C++有值传递和引用传递，引用参数用&amp;符号表示。 2.情况分析2.1.参数为基本类型，方法内改变参数的值123456public void static tripleValue(int x)&#123; x = x * 3; //percent值不变&#125;int percent = 10;tripleValue(percent);System.out.println(percent); 调用这个方法后percent的值还是10，执行过程如下： x被初始化为percent值得一个拷贝（也就是10）。 x被乘以3后等于30,但是percent仍然是10。 这个方法结束后，参数变量x不再使用。如图:2.2.参数为对象引用，修改对象的状态12345public static void tripleSalary(Employee x)&#123; x.salary = x.salary * 3; //harry的salary属性变了&#125;harry = new Emploee(...);tripleSalary(harry); 调用这个方法后harry的salary属性变成原来的3倍，执行过程： x被初始化为harry值的拷贝，这里是一个对象的引用。 tripleSalary()方法应用于这个对象应用。x和harry同时引用的那个Employee对象的薪金乘以3。 方法结束后，参数变量x不再使用。但对象变量harry继续用用那个薪金增至3倍的雇员对象。如图:2.3.参数为对象引用，交换这2个对象引用12345678pulic static void swap(Employee x, Employee y)&#123; Employee tmp = x; x = y; y = tmep; //crs和cai没有交换&#125;Employee crs = new Employee(...);Employee cai = new Employee(...);swap(crs,cai); 调用这个方法后crs和cai这两个对象没有交换成功。执行过程：1.x被初始化为crs对象引用的拷贝，y被初始化为cai对象引用的拷贝。2.交换的是这两个拷贝。3.在方法结束后，x,y被丢弃了。原来的变量crs和cai仍然引用这个方法调用之前所引用的对象。如图: 3.总结Java中方法参数的使用情况： 一个方法不能修改一个基本数据类型的参数（即数值型或布尔值）。 一个方法可以改变一个对象参数的状态。 一个方法不能让对象参数引用一个新的对象（包括String）。","categories":[{"name":"JAVA基础","slug":"JAVA基础","permalink":"https://reasoncai.github.io/categories/JAVA基础/"}],"tags":[]},{"title":"调用外网第三方接口的坑与架构优化方案","slug":"调用外网第三方接口的坑与架构优化方案","date":"2017-05-27T15:51:14.000Z","updated":"2017-05-28T10:47:02.000Z","comments":true,"path":"2017/05/27/调用外网第三方接口的坑与架构优化方案/","link":"","permalink":"https://reasoncai.github.io/2017/05/27/调用外网第三方接口的坑与架构优化方案/","excerpt":"","text":"1.问题背景我们的业务系统经常需要调用第三方提供的接口（通常都是公网），常用的做法是将第三方提供的接口抽象成一个服务。这样第三方接口发生变动时，只需要修改这个服务，不用修改所有的调用方，使调用方与第三方接口解耦。 调用的流程如下图： 业务调用方调用内部service 内部service跨公网调用第三方接口 第三方接口返回结果给内部service 内部service返回结果给业务调用方 这个过程中会存在一个问题，如下图：内部服务可能对上游业务提供了很多服务接口，当有一个接口跨公网第三方调用超时时，可能导致所有接口都不可用，即使大部分接口不依赖于跨公网第三方调用。 为什么会出现这种情况呢？ 内部服务对业务方提供的N个接口，会共用服务容器内的工作线程（假设有100个工作线程）。 假设这N个接口的某个接口跨公网依赖于第三方的接口，发生了网络抖动，或者接口超时（不妨设超时时间为5秒）。 潜台词是，这个工作线程会被占用5秒钟，然后超时返回业务调用方。 假设这个请求的吞吐量为20qps，言下之意，很短的时间内，所有的100个工作线程都会被卡在这个第三方超时等待上，而其他N-1个原本没有问题的接口，也得不到工作线程处理。 2.优化方案 增大工作线程数（不根本解决问题） 降低超时时间（不根本解决问题） 垂直拆分，N个接口拆分成若干个服务，使得在出问题时，被牵连的接口尽可能少（依旧不根本解决问题，难道一个服务只提供一个接口吗？）2.1.异步代理法 业务场景：通过OpenID实时获取微信用户基本信息 解决方案：增加一个代理，向服务屏蔽究竟是“本地实时”还是“异步远程”去获取返回结果本地实时流程如上图： 业务调用方调用内部service 内部service调用异步代理service 异步代理service通过OpenID在本地拿取数据 异步代理service将数据返回内部service 内部service返回结果给业务调用方 异步远程流程如上图6-8粗箭头的部分： 异步代理service定期跨公网调用微信服务 微信服务返回数据 刷新本地数据 优点：公网抖动，第三方接口超时，不影响内部接口调用 不足：本地返回的不是最新数据（很多业务可以接受数据延时） 有时候，内部service和异步代理service可以合成一个service 2.2.异步调用法 业务场景：本地结果，同步第三方服务。例如业务系统调用本地消息中心的短信接口发短信，消息中心记录到本地的数据库后，立刻返回成功给业务系统。实际上消息中心再异步调用外网第三方短信接口。 解决方案：本地调用成功就返回成功，异步调用第三方接口同步数据（和异步代理有微小差别）本地流程如上图1-3： 业务调用方调用内部service 内部service写本地数据 内部service返回结果给业务调用方成功 异步流程如上图4-5粗箭头的部分： 异步service定期将本地数据取出（或者通知(可用MQ)也行，实时性好） 异步调用第三方接口同步数据 优点：公网抖动，第三方接口超时，不影响内部接口调用 不足：不是所有业务场景都可以异步同步数据 3.总结跨公网调用第三方，可能存在的问题： 公网抖动，第三方服务不稳定，影响自身服务 一个接口超时，占住工作线程，影响其他接口 降低影响的优化方案： 增大工作线程数 降低超时时间 服务垂直拆分 业务需求决定技术方案，结合业务的解决方案： 业务能接受旧数据：读取本地数据，异步代理定期更新数据(适用于获取第三方提供的信息且要求的实时性不高的场景) 向第三方同步数据：本地写成功就算成功，异步向第三方同步数据（适用于不需要第三方即时返回结果的场景） 拓展方案： 使用Hystrix的超时机制和断路器","categories":[{"name":"架构","slug":"架构","permalink":"https://reasoncai.github.io/categories/架构/"}],"tags":[]},{"title":"ThreadPoolExcutor线程池的使用","slug":"ThreadPoolExcutor线程池的使用","date":"2017-05-23T15:39:30.000Z","updated":"2017-05-28T15:53:35.000Z","comments":true,"path":"2017/05/23/ThreadPoolExcutor线程池的使用/","link":"","permalink":"https://reasoncai.github.io/2017/05/23/ThreadPoolExcutor线程池的使用/","excerpt":"","text":"1.基本概念线程池类为 Java.util.concurrent.ThreadPoolExecutor，常用构造方法为：12345678910ThreadPoolExecutor(int corePoolSize, int maximumPoolSize,long keepAliveTime, TimeUnit unit,BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler)corePoolSize： 线程池维护线程的最少数量maximumPoolSize：线程池维护线程的最大数量keepAliveTime： 线程池维护线程所允许的空闲时间unit： 线程池维护线程所允许的空闲时间的单位workQueue： 线程池所使用的缓冲队列handler： 线程池对拒绝任务的处理策略 一个任务通过 execute(Runnable)方法被添加到线程池，任务就是一个 Runnable类型的对象，任务的执行方法就是 Runnable类型对象的run()方法。当一个任务通过execute(Runnable)方法欲添加到线程池时： 如果此时线程池中的数量小于corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。 如果此时线程池中的数量等于 corePoolSize，但是缓冲队列 blockQueue未满，那么任务被放入缓冲队列。 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量小于maximumPoolSize，建新的线程来处理被添加的任务。 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量等于maximumPoolSize，那么通过 handler所指定的策略来处理此任务。 也就是：处理任务的优先级为：核心线程corePoolSize、任务队列workQueue、最大线程maximumPoolSize，如果三者都满了，使用handler处理被拒绝的任务。 当线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止。这样，线程池可以动态的调整池中的线程数。 work queue有以下几种实现： ArrayBlockingQueue : 有界的数组队列 LinkedBlockingQueue : 可支持有界/无界的队列，使用链表实现 PriorityBlockingQueue : 优先队列，可以针对任务排序 SynchronousQueue : 队列长度为1的队列，和Array有点区别就是：client thread提交到block queue会是一个阻塞过程，直到有一个worker thread连接上来poll task。 workQueue常用的是：java.util.concurrent.ArrayBlockingQueue handler有四个选择：12345678ThreadPoolExecutor.AbortPolicy()抛出java.util.concurrent.RejectedExecutionException异常ThreadPoolExecutor.CallerRunsPolicy()直接让原先的client thread做为worker线程，进行执行ThreadPoolExecutor.DiscardOldestPolicy()丢弃最早入队列的的任务ThreadPoolExecutor.DiscardPolicy()抛弃当前的任务 2.建议2.1.ThreadPoolExecutor允许你提供一个BlockingQueue来持有等待执行的任务。任务排队有3种基本方法：无限队列、有限队列和同步移交。2.2.newFixedThreadPool和newSingleThreadExectuor默认使用的是一个无限的 LinkedBlockingQueue。如果所有的工作者线程都处于忙碌状态，任务会在队列中等候。如果任务持续快速到达，超过了它们被执行的速度，队列也会无限制地增加。稳妥的策略是使用有限队列，比如ArrayBlockingQueue或有限的LinkedBlockingQueue以及 PriorityBlockingQueue。2.3.对于庞大或无限的池，可以使用SynchronousQueue，完全绕开队列，直接将任务由生产者交给工作者线程2.4.可以使用PriorityBlockingQueue通过优先级安排任务2.5.善用blockqueue和reject组合.这里要重点推荐下CallsRun的Rejected Handler，从字面意思就是让调用者自己来运行。我们经常会在线上使用一些线程池做异步处理 将原本串行的请求都变为了并行操作，但过多的并行会增加系统的负载(比如软中断，上下文切换)。所以肯定需要对线程池做一个size限制。但是为了引入异步操作后，避免因在block queue的等待时间过长，所以需要在队列满的时，执行一个callsRun的策略，并行的操作又转为一个串行处理，这样就可以保证尽量少的延迟影响。 所以建议： maximumPoolSize &gt;= corePoolSize =期望的最大线程数 RejectExecutionHandler = CallsRun , blockqueue size = 2 * poolSize (为啥是2倍poolSize，主要一个考虑就是瞬间高峰处理，允许一个thread等待一个runnable任务) 2.6.队列维护方法 getQueue() 允许出于监控和调试目的而访问工作队列。强烈反对出于其他任何目的而使用此方法。remove(java.lang.Runnable) 和 purge() 这两种方法可用于在取消大量已排队任务时帮助进行存储回收。 3.扩展ThreadPoolExecutor是可扩展的，通过查看源码可以发现，它提供了几个可以在子类化中改写的方法：beforeExecute,afterExecute,terminated.123protected void beforeExecute(Thread t, Runnable r) &#123; &#125; protected void afterExecute(Runnable r, Throwable t) &#123; &#125; protected void terminated() &#123; &#125; 可以注意到，这三个方法都是protected的空方法，摆明了是让子类扩展的嘛。在执行任务的线程中将调用beforeExecute和afterExecute等方法，在这些方法中还可以添加日志、计时、监视或者统计信息收集的功能。无论任务是从run中正常返回，还是抛出一个异常而返回，afterExecute都会被调用。如果任务在完成后带有一个Error，那么就不会调用afterExecute。如果beforeExecute抛出一个RuntimeException，那么任务将不被执行，并且afterExecute也不会被调用。在线程池完成关闭时调用terminated，也就是在所有任务都已经完成并且所有工作者线程也已经关闭后，terminated可以用来释放Executor在其生命周期里分配的各种资源，此外还可以执行发送通知、记录日志或者手机finalize统计等操作。 下面就以给线程池添加统计信息为例（添加日志和计时等功能）：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.threadPool; import java.util.concurrent.BlockingQueue; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; import java.util.concurrent.atomic.AtomicLong; import java.util.logging.Logger; public class TimingThreadPool extends ThreadPoolExecutor &#123; private final ThreadLocal&lt;Long&gt; startTime = new ThreadLocal&lt;Long&gt;(); private final Logger log = Logger.getAnonymousLogger(); private final AtomicLong numTasks = new AtomicLong(); private final AtomicLong totalTime = new AtomicLong(); public TimingThreadPool(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue); &#125; protected void beforeExecute(Thread t, Runnable r)&#123; super.beforeExecute(t, r); log.info(String.format(\"Thread %s: start %s\", t,r)); startTime.set(System.nanoTime()); &#125; protected void afterExecute(Runnable r, Throwable t)&#123; try&#123; long endTime = System.nanoTime(); long taskTime = endTime-startTime.get(); numTasks.incrementAndGet(); totalTime.addAndGet(taskTime); log.info(String.format(\"Thread %s: end %s, time=%dns\", t,r,taskTime)); &#125; finally &#123; super.afterExecute(r, t); &#125; &#125; protected void terminated() &#123; try &#123; log.info(String.format(\"Terminated: avg time=%dns\",totalTime.get()/numTasks.get())); &#125; finally &#123; super.terminated(); &#125; &#125; &#125; 下面写一个测试类，参考运行效果：1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.threadPool; import java.util.concurrent.SynchronousQueue; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; public class CheckTimingThreadPool &#123; public static void main(String[] args) &#123; ThreadPoolExecutor exec = new TimingThreadPool(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); exec.execute(new DoSomething(5)); exec.execute(new DoSomething(4)); exec.execute(new DoSomething(3)); exec.execute(new DoSomething(2)); exec.execute(new DoSomething(1)); exec.shutdown(); &#125; &#125; class DoSomething implements Runnable&#123; private int sleepTime; public DoSomething(int sleepTime) &#123; this.sleepTime = sleepTime; &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+\" is running.\"); try &#123; TimeUnit.SECONDS.sleep(sleepTime); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;","categories":[{"name":"JAVA基础","slug":"JAVA基础","permalink":"https://reasoncai.github.io/categories/JAVA基础/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://reasoncai.github.io/tags/多线程/"},{"name":"并发","slug":"并发","permalink":"https://reasoncai.github.io/tags/并发/"}]},{"title":"58到家数据库军规解读","slug":"58到家数据库军规解读","date":"2017-05-22T15:44:50.000Z","updated":"2017-05-22T15:47:03.000Z","comments":true,"path":"2017/05/22/58到家数据库军规解读/","link":"","permalink":"https://reasoncai.github.io/2017/05/22/58到家数据库军规解读/","excerpt":"","text":"军规适用场景：并发量大、数据量大的互联网业务军规：介绍内容解读：讲解原因，解读比军规更重要 一、基础规范 （1）必须使用InnoDB存储引擎解读：支持事务、行级锁、并发性能更好、CPU及内存缓存页优化使得资源利用率更高 （2）必须使用UTF8字符集(最好用utf8mb4,utf8mb4是utf8的超集，emoji表情以及部分不常见汉字在utf8下会表现为乱码，故需要升级至utf8mb4。)解读：万国码，无需转码，无乱码风险。 （3）数据表、数据字段必须加入中文注释解读：N年后谁tm知道这个r1,r2,r3字段是干嘛的 （4）禁止使用存储过程、视图、触发器、Event解读：高并发大数据的互联网业务，架构设计思路是“解放数据库CPU，将计算转移到服务层”，并发量大的情况下，这些功能很可能将数据库拖死，业务逻辑放到服务层具备更好的扩展性，能够轻易实现“增机器就加性能”。数据库擅长存储与索引，CPU计算还是上移吧 （5）禁止存储大文件或者大照片解读：为何要让数据库做它不擅长的事情？大文件和照片存储在文件系统，数据库里存URI多好 二、命名规范（6）只允许使用内网域名，而不是ip连接数据库 （7）线上环境、开发环境、测试环境数据库内网域名遵循命名规范业务名称：xxx线上环境：dj.xxx.db开发环境：dj.xxx.rdb测试环境：dj.xxx.tdb从库在名称后加-s标识，备库在名称后加-ss标识线上从库：dj.xxx-s.db线上备库：dj.xxx-sss.db （8）库名、表名、字段名：小写，下划线风格，不超过32个字符，必须见名知意，禁止拼音英文混用 （9）表名t_xxx，非唯一索引名idx_xxx，唯一索引名uniq_xxx 三、表设计规范 （10）单实例表数目必须小于500 （11）单表列数目必须小于30 （12）表必须有主键，例如自增主键解读： a）主键递增，数据行写入可以提高插入性能，可以避免page分裂，减少表碎片提升空间和内存的使用 b）主键要选择较短的数据类型， Innodb引擎普通索引都会保存主键的值，较短的数据类型可以有效的减少索引的磁盘空间，提高索引的缓存效率 c） 无主键的表删除，在row模式的主从架构，会导致备库夯住 （13）禁止使用外键，如果有外键完整性约束，需要应用程序控制解读：外键会导致表与表之间耦合，update与delete操作都会涉及相关联的表，十分影响sql 的性能，甚至会造成死锁。高并发情况下容易造成数据库性能，大数据高并发业务场景数据库使用以性能优先 四、字段设计规范 （14）必须把字段定义为NOT NULL并且提供默认值解读：a）null的列使索引/索引统计/值比较都更加复杂，对MySQL来说更难优化b）null 这种类型MySQL内部需要进行特殊处理，增加数据库处理记录的复杂性；同等条件下，表中有较多空字段的时候，数据库的处理性能会降低很多c）null值需要更多的存储空，无论是表还是索引中每行中的null的列都需要额外的空间来标识d）对null 的处理时候，只能采用is null或is not null，而不能采用=、in、&lt;、&lt;&gt;、!=、not in这些操作符号。如：where name!=’shenjian’，如果存在name为null值的记录，查询结果就不会包含name为null值的记录 （15）禁止使用TEXT、BLOB类型解读：会浪费更多的磁盘和内存空间，非必要的大量的大字段查询会淘汰掉热数据，导致内存命中率急剧降低，影响数据库性能 （16）禁止使用小数存储货币解读：使用整数吧，小数容易导致钱对不上，可以使单位为分 （17）必须使用varchar(20)存储手机号解读：a）涉及到区号或者国家代号，可能出现+-()b）手机号会去做数学运算么？c）varchar可以支持模糊查询，例如：like“138%” （18）禁止使用ENUM，可使用TINYINT代替解读：a）增加新的ENUM值要做DDL操作b）ENUM的内部实际存储就是整数，你以为自己定义的是字符串？ 五、索引设计规范 （19）单表索引建议控制在5个以内 （20）单索引字段数不允许超过5个解读：字段超过5个时，实际已经起不到有效过滤数据的作用了 （21）禁止在更新十分频繁、区分度不高的属性上建立索引解读：a）更新会变更B+树，更新频繁的字段建立索引会大大降低数据库性能b）“性别”这种区分度不大的属性，建立索引是没有什么意义的，不能有效过滤数据，性能与全表扫描类似 （22）建立组合索引，必须把区分度高的字段放在前面解读：能够更加有效的过滤数据 六、SQL使用规范 （23）禁止使用SELECT ，只获取必要的字段，需要显示说明列属性解读：a）读取不需要的列会增加CPU、IO、NET消耗b）不能有效的利用覆盖索引c）使用SELECT 容易在增加或者删除字段后出现程序BUG （24）禁止使用INSERT INTO t_xxx VALUES(xxx)，必须显示指定插入的列属性解读：容易在增加或者删除字段后出现程序BUG （25）禁止使用属性隐式转换解读：SELECT uid FROM t_user WHERE phone=13812345678 会导致全表扫描，而不能命中phone索引，猜猜为什么？（这个线上问题不止出现过一次，因为phone是varchar类型，SQL语句带入的是整形，故不会命中索引，加个引号就好了：SELECT uid FROM t_user WHERE phone=’13812345678’ （26）禁止在WHERE条件的属性上使用函数或者表达式解读：SELECT uid FROM t_user WHERE from_unixtime(day)&gt;=’2017-02-15’ 会导致全表扫描正确的写法是：SELECT uid FROM t_user WHERE day&gt;= unix_timestamp(‘2017-02-15 00:00:00’) （27）禁止负向查询，以及%开头的模糊查询解读：a）负向查询条件：NOT、!=、&lt;&gt;、!&lt;、!&gt;、NOT IN、NOT LIKE等，会导致全表扫描b）%开头的模糊查询，会导致全表扫描 （28）禁止大表使用JOIN查询，禁止大表使用子查询解读：会产生临时表，消耗较多内存与CPU，极大影响数据库性能 （29）禁止使用OR条件，必须改为IN查询解读：旧版本Mysql的OR查询是不能命中索引的，即使能命中索引，为何要让数据库耗费更多的CPU帮助实施查询优化呢？ （30）应用程序必须捕获SQL异常，并有相应处理 七、行为规范 （31）禁止使用应用程序配置文件内的帐号手工访问线上数据库 （32）禁止非DBA对线上数据库进行写操作，修改线上数据需要提交工单，由DBA执行，提交的SQL语句必须经过测试 （33）分配非DBA以只读帐号，必须通过VPN+跳板机访问授权的从库 （34）开发、测试、线上环境隔离 为什么要制定行为规范的军规呢，大伙的公司是不是有这样的情况：任何研发、测试都有连接线上数据库的帐号？ 是不是经常有这类误操作？ （1）本来只想update一条记录，where条件搞错，update了全部的记录 （2）本来只想delete几行记录，结果删多了，四下无人，再insert回去 （3）以为drop的是测试库，结果把线上库drop掉了 （4）以为操作的是分库x，结果SecureCRT开窗口太多，操作成了分库y （5）写错配置文件，压力测试压到线上库了，生成了N多脏数据… 无数的事情，结果就是打电话给DBA，让他们帮忙擦屁股。… 所谓的“业务灵活性”都是扯淡，为什么要有行为规范？不让你带刀，不是限制你，而是保护你的安全。要相信DBA是专业的，让专业的人干专业的事情。别把DBA看做你的对立面，多和他们沟通业务场景，沟通请求读写比，沟通访问模式，他们真的能帮助到你，这是我带DBA团队的一些感触。 总结：大数据量高并发的互联网业务，极大影响数据库性能的都不让用，不让用哟。谁都可能删除全库，能找回数据的，真的只有DBA。 转自：58沈剑公众号：架构师之路","categories":[{"name":"转载","slug":"转载","permalink":"https://reasoncai.github.io/categories/转载/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://reasoncai.github.io/tags/数据库/"},{"name":"SQL","slug":"SQL","permalink":"https://reasoncai.github.io/tags/SQL/"}]},{"title":"linux-grep命令详解","slug":"linux-grep命令详解","date":"2017-05-21T04:30:48.000Z","updated":"2017-05-21T04:36:00.000Z","comments":true,"path":"2017/05/21/linux-grep命令详解/","link":"","permalink":"https://reasoncai.github.io/2017/05/21/linux-grep命令详解/","excerpt":"","text":"grep 、sed、awk被称为linux中的”三剑客”。 grep 更适合单纯的查找或匹配文本 sed 更适合编辑匹配到的文本 awk 更适合格式化文本，对文本进行较复杂格式处理 先说说grep命令能做什么？ 我们可以使用grep命令在文本中查找指定的字符串，就像你在windows中打开txt文件，使用快捷键 “Ctrl+F” 在文本中查找某个字符串一样，说白了，可以把grep理解成字符查找工具。 grep的全称为： Global search Regular Expression and Print out the line 全称中的”Global search”为全局搜索之意。 全称中的”Regular Expression”表示正则表达式。 所以，从grep的全称中可以了解到，grep是一个可以利用”正则表达式”进行”全局搜索”的工具，grep会在文本文件中按照指定的正则进行全局搜索，并将搜索出的行打印出来。 Unix的grep家族包括grep、egrep和fgrep。egrep和fgrep的命令只跟grep有很小不同。egrep是grep的扩展，支持更多的re元字符， fgrep就是fixed grep或fast grep，它们把所有的字母都看作单词，也就是说，正则表达式中的元字符表示回其自身的字面意义，不再特殊。linux使用GNU版本的grep。它功能更强，可以通过-G、-E、-F命令行选项来使用egrep和fgrep的功能。 当然，不使用正则表达式时也可以使用grep，但是当grep与正则表达式结合在一起时，威力更强大。 grep的常用选项总结如下 –color=auto 或者 –color：表示对匹配到的文本着色显示 -i：在搜索的时候忽略大小写 -n：显示结果所在行号 -c：统计匹配到的行数，注意，是匹配到的总行数，不是匹配到的次数 -o：只显示符合条件的字符串，但是不整行显示，每个符合条件的字符串单独显示一行 -v：输出不带关键字的行（反向查询，反向匹配） -w：匹配整个单词，如果是字符串中包含这个单词，则不作匹配 －l：查询多文件时只输出包含匹配字符的文件名。 -Ax：在输出的时候包含结果所在行之后的指定行数，这里指之后的x行，A：after -Bx：在输出的时候包含结果所在行之前的指定行数，这里指之前的x行，B：before -Cx：在输出的时候包含结果所在行之前和之后的指定行数，这里指之前和之后的x行，C：context -e：实现多个选项的匹配，逻辑or关系 -q：静默模式，不输出任何信息，当我们只关心有没有匹配到，却不关心匹配到什么内容时，我们可以使用此命令，然后，使用”echo $?”查看是否匹配到，0表示匹配到，1表示没有匹配到。 -P：表示使用兼容perl的正则引擎。 -E：使用扩展正则表达式，而不是基本正则表达式，在使用”-E”选项时，相当于使用egrep。12345678910pattern正则表达式主要参数：\\： 忽略正则表达式中特殊字符的原有含义。^：匹配正则表达式的开始行。$: 匹配正则表达式的结束行。\\&lt;：从匹配正则表达 式的行开始。\\&gt;：到匹配正则表达式的行结束。[ ]：单个字符，如[A]即A符合要求 。[ - ]：范围，如[A-Z]，即A、B、C一直到Z都符合要求 。。：所有的单个字符。* ：有字符，长度可以为0。 grep的常用用法12345678910[root@www ~]# grep [-acinv] [--color=auto] '搜寻字符串' filename$ grep ‘test’ d*显示所有以d开头的文件中包含 test的行。$ grep ‘test’ aa bb cc显示在aa，bb，cc文件中匹配test的行。$ grep ‘[a-z]\\&#123;5\\&#125;’ aa显示所有包含每个字符串至少有5个连续小写字符的字符串的行。$ grep ‘w\\(es\\)t.*\\1′ aa如果west被匹配，则es就被存储到内存中，并标记为1，然后搜索任意个字符(.*)，这些字符后面紧跟着 另外一个es(\\1)，找到就显示该行。如果用egrep或grep -E，就不用”\\”号进行转义，直接写成’w(es)t.*\\1′就可以了。 grep 可以使用 –color=auto 来将关键字部分使用颜色显示。 可以用alias 来处理一下可以在 ~/.bashrc 内加上这行：『alias grep=’grep –color=auto’』再以『 source ~/.bashrc 』来立即生效. 根据文件内容递归查找目录1234$ grep ‘test’ * #在当前目录搜索带'test'行的文件$ grep -r ‘test’ * #在当前目录及其子目录下搜索'test'行的文件$ grep -l -r ‘test’ * #在当前目录及其子目录下搜索'test'行的文件，但是不显示匹配的行，只显示匹配的文件","categories":[{"name":"linux","slug":"linux","permalink":"https://reasoncai.github.io/categories/linux/"}],"tags":[{"name":"linux命令","slug":"linux命令","permalink":"https://reasoncai.github.io/tags/linux命令/"}]},{"title":"mongodb并发连接数","slug":"mongodb并发连接数","date":"2017-05-19T16:01:49.000Z","updated":"2017-05-19T16:05:49.000Z","comments":true,"path":"2017/05/20/mongodb并发连接数/","link":"","permalink":"https://reasoncai.github.io/2017/05/20/mongodb并发连接数/","excerpt":"","text":"高并发时生产应用出现mongodb连接超时的异常：com.mongodb.DBPortPool$ConnectionWaitTimeOut: Connection wait timeout after 120000 ms 查看mongodb服务器当前连接数12345#./mongo admin -u admin -p adminMongoDB shell version: 2.2.0connecting to: admin&gt; db.serverStatus().connections;&#123; \"current\" : 174, \"available\" : 645 &#125; 不是mongodb自身的原因，查看应用的mongodb的连接池最大连接数connectionsPerHost原来只设了50，调大到200解决。(PS:网上有资料说Mongodb某个版本的java驱动有这个bug) 附资料：关于MONGODB最大连接数的查看与修改 在Linux平台下，无论是64位或者32位的MongoDB默认最大连接数都是819，WIN平台不知道，估计也没有人在 WIN平台下使用MongoDB做生产环境12345[root@DELL113 mongodb-linux-i686-2.4.1]# mongo admin -u root -p passwordMongoDB shell version: 2.4.1connecting to: 192.168.6.42/admin&gt; db.serverStatus().connections&#123; \"current\" : 1, \"available\" : 818, \"totalCreated\" : NumberLong(1) &#125; 途中available显示818少了一个，表示空闲的。current表示已经占用了的连接数，两数一加就等于819，如果我现在在连接一个，那么available就是817，current就是21234567[root@DELL113 mongodb-linux-i686-2.4.1]# ./bin/mongo 192.168.6.42MongoDB shell version: 2.4.1connecting to: 192.168.6.42/test&gt; db.serverStatus().connections&#123; \"current\" : 1, \"available\" : 818, \"totalCreated\" : NumberLong(1) &#125;&gt; db.serverStatus().connections&#123; \"current\" : 2, \"available\" : 817, \"totalCreated\" : NumberLong(2) &#125; 819个连接数对于一般的站点我认为已经够用，并且都是现连现取现断。但这个连接数也可以修改，只要在启动的时候加入–maxConns即可服务器启动1234567891011121314[root@lee mongodb-linux-x86_64-2.4.1]# ./bin/mongod --dbpath=/root/db --maxConns=2000Wed Apr 3 11:06:21.905 [initandlisten] MongoDB starting : pid=2812 port=27017 dbpath=/root/db 64-bit host=leeWed Apr 3 11:06:21.957 [initandlisten] db version v2.4.1Wed Apr 3 11:06:21.957 [initandlisten] git version: 1560959e9ce11a693be8b4d0d160d633eee75110Wed Apr 3 11:06:21.957 [initandlisten] build info: Linux ip-10-2-29-40 2.6.21.7-2.ec2.v1.2.fc8xen #1 SMP Fri Nov 20 17:48:28 EST 2009 x86_64 BOOST_LIB_VERSION=1_49Wed Apr 3 11:06:21.957 [initandlisten] allocator: tcmallocWed Apr 3 11:06:21.957 [initandlisten] options: &#123; dbpath: \"/root/db\", maxConns: 2000 &#125;Wed Apr 3 11:06:21.982 [initandlisten] journal dir=/root/db/journalWed Apr 3 11:06:21.982 [initandlisten] recover : no journal files present, no recovery neededWed Apr 3 11:06:22.297 [initandlisten] preallocateIsFaster=true 2.62Wed Apr 3 11:06:22.717 [initandlisten] --maxConns too high, can only handle 819Wed Apr 3 11:06:22.724 [initandlisten] waiting for connections on port 27017Wed Apr 3 11:06:22.725 [websvr] admin web console waiting for connections on port 28017Wed Apr 3 11:06:25.126 [initandlisten] connection accepted from 192.168.4.86:53917 #1 (1 connection now open) 查询最大连接数123456[root@DELL113 mongodb-linux-i686-2.4.1]# ./bin/mongo 192.168.6.42MongoDB shell version: 2.4.1connecting to: 192.168.6.42/test&gt; db.serverStatus().connections&#123; \"current\" : 1, \"available\" : 818, \"totalCreated\" : NumberLong(1) &#125;&gt; 发现还是819？其实是Linux默认进程能打开最大文件数有关，可以通过ulimit 解决12345678910111213[root@lee mongodb-linux-x86_64-2.4.1]# ulimit -n 2500[root@lee mongodb-linux-x86_64-2.4.1]# ./bin/mongod --dbpath=/root/db --maxConns=2000Wed Apr 3 11:11:07.013 [initandlisten] MongoDB starting : pid=2930 port=27017 dbpath=/root/db 64-bit host=leeWed Apr 3 11:11:07.013 [initandlisten] db version v2.4.1Wed Apr 3 11:11:07.013 [initandlisten] git version: 1560959e9ce11a693be8b4d0d160d633eee75110Wed Apr 3 11:11:07.013 [initandlisten] build info: Linux ip-10-2-29-40 2.6.21.7-2.ec2.v1.2.fc8xen #1 SMP Fri Nov 20 17:48:28 EST 2009 x86_64 BOOST_LIB_VERSION=1_49Wed Apr 3 11:11:07.013 [initandlisten] allocator: tcmallocWed Apr 3 11:11:07.013 [initandlisten] options: &#123; dbpath: \"/root/db\", maxConns: 2000 &#125;Wed Apr 3 11:11:07.031 [initandlisten] journal dir=/root/db/journalWed Apr 3 11:11:07.031 [initandlisten] recover : no journal files present, no recovery neededWed Apr 3 11:11:07.170 [initandlisten] waiting for connections on port 27017Wed Apr 3 11:11:07.171 [websvr] admin web console waiting for connections on port 28017Wed Apr 3 11:11:10.076 [initandlisten] connection accepted from 192.168.4.86:53161 #1 (1 connection now open) 再查看最大连接数，搞定123456[root@DELL113 mongodb-linux-i686-2.4.1]# ./bin/mongo 192.168.6.42MongoDB shell version: 2.4.1connecting to: 192.168.6.42/test&gt; db.serverStatus().connections&#123; \"current\" : 1, \"available\" : 1999, \"totalCreated\" : NumberLong(1) &#125;&gt; 关于ulimit的更多知识大家可以去网上检索检索 客户端程序通常是通过DRIVER来链接，由于每次建立链接的成本都挺高，因此都用链接池来实现，SPRING DATA MONGODB中是如下配置123456789101112mongo.dbname=cms#线程池的大小mongo.connectionsPerHost=100#这个*mongo.connectionsPerHost则是如果链接数大于100的等待xttk数mongo.threadsAllowedToBlockForConnectionMultiplier=4#等待线程的等待时间mongo.maxWaitTime=1500mongo.socketTimeout=1500mongo.connectTimeout=1000mongo.autoConnectRetry=truemongo.socketKeepAlive=truemongo.slaveOk=true","categories":[{"name":"工作笔记","slug":"工作笔记","permalink":"https://reasoncai.github.io/categories/工作笔记/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"https://reasoncai.github.io/tags/mongodb/"}]},{"title":"Spring缓存使用方法(基于注解)","slug":"Spring缓存使用方法(基于注解)","date":"2017-05-10T15:24:19.000Z","updated":"2017-05-12T16:52:35.000Z","comments":true,"path":"2017/05/10/Spring缓存使用方法(基于注解)/","link":"","permalink":"https://reasoncai.github.io/2017/05/10/Spring缓存使用方法(基于注解)/","excerpt":"","text":"1.启用Spring对缓存的支持。Spring对缓存的支持有两种方式： 注解驱动的缓存 XML声明的缓存1.1.通过使用@EnableCaching启用注解驱动的缓存 1234567891011121314151617181920212223package com.cai.springcache.config;import org.springframework.cache.CacheManager;import org.springframework.cache.annotation.EnableCaching;import org.springframework.cache.concurrent.ConcurrentMapCacheManager;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * Created by reason on 17/5/11. */@Configuration@EnableCaching //启用缓存public class CacheConfig &#123; /** * 声明缓存管理器 * @return */ @Bean public CacheManager cacheManager()&#123; return new ConcurrentMapCacheManager(); &#125;&#125; 1.2.通过使用&lt;cache:annotation-driven/&gt;启用注解式缓存12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:cache=\"http://www.springframework.org/schema/cache\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/cache http://www.springframework.org/schema/cache/spring-cache.xsd\"&gt; &lt;!--启用注解式缓存--&gt; &lt;cache:annotation-driven/&gt; &lt;!--声明缓存管理器--&gt; &lt;bean id = \"cacheManager\" class= \"org.springframework.cache.concurrent.ConcurrentMapCacheManager\"/&gt;&lt;/beans&gt; 以上两种方式的工作原理是相同的，都是创建一个切面(aspect)并触发Spring缓存注解的切点(pointcut)。根据所使用的注解以及缓存的状态，切面会从缓存中获取数据，将数据添加到缓存中或者从缓存中移除某个值。例子中出了启用了注解驱动的缓存，还声明了一个缓存管理器(cache manager)的bean。缓存管理器是Spring缓存的抽象核心，它能够与多个流行的缓存实现(Ehcache,Redis等等)进行集成。例子中用了ConcurrentMapCacheManager这个简单的缓存管理器，底层其实就是用了ConcurrentHashMap作为存储，其存储是基于内存额，适用于开发，测试或简单的应用。 1.3.配置缓存管理器可用的缓存管理器： SimpleCacheManager NoOpCacheManager ConcurrentMapCacheManager CompositeCacheManager EhCacheCacheManager JCacheCacheManager RedisCacheManager GemfireCacheManager 使用Ehcache缓存 需要依赖ehcache 1.3.1.以Java配置的方式设置EhCacheCacheManager123456789101112131415161718192021222324252627package com.cai.springcache.config;import net.sf.ehcache.CacheManager;import org.springframework.cache.annotation.EnableCaching;import org.springframework.cache.ehcache.EhCacheCacheManager;import org.springframework.cache.ehcache.EhCacheManagerFactoryBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.io.ClassPathResource;/** * Created by reason on 17/5/11. */@Configuration@EnableCachingpublic class EhCacheConfig &#123; @Bean public EhCacheCacheManager cacheCacheManager(CacheManager cm)&#123; return new EhCacheCacheManager(cm); &#125; @Bean public EhCacheManagerFactoryBean ehcache()&#123; EhCacheManagerFactoryBean ehCacheManagerFactoryBean = new EhCacheManagerFactoryBean(); ehCacheManagerFactoryBean.setConfigLocation(new ClassPathResource(\"ehcache.xml\")); return ehCacheManagerFactoryBean; &#125;&#125; 说明：EhCache的CacheManager要被注入到Spring的EhCacheCacheManager之中。Spring提供了EhCacheManagerFactoryBean来生成EhCache的CacheManager。方法ehcache()会创建并返回一个EhCacheManagerFactoryBean实例。因为它是一个工厂bean（实现了Spring的FactoryBean接口），所以注册在Spring应用上下文中的并不是EhCacheManagerFactoryBean的实例，而是CacheManager的一个实例。1234&lt;ehcache&gt; &lt;cache name=\"test\" maxBytesLocalHeap=\"50m\" timeToLiveSeconds=\"100\"&gt; &lt;/cache&gt;&lt;/ehcache&gt; ehcache.xml的配置示例 使用Redis缓存 需要依赖spring-data-redis spring-data-redis提供了RedisCacheManager,这是CacheManager的一个实现。RedisCacheManager通过RedisTemplate将缓存存到Redis中。为了使用RedisCacheManager,需要RedisTemplate和RedisConnectionFactory实现类(如JedisConnectionFactory)的一个bean. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.cai.springcache.config;import org.springframework.cache.CacheManager;import org.springframework.cache.annotation.EnableCaching;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.cache.RedisCacheManager;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;/** * Created by reason on 17/5/11. */@Configuration@EnableCachingpublic class RedisCacheConfig &#123; /** * Redis缓存管理器 * @param redisTemplate * @return */ @Bean public CacheManager cacheManager(RedisTemplate redisTemplate)&#123; return new RedisCacheManager(redisTemplate); &#125; /** * RedisTemplate * @param redisConnectionFactory * @return */ @Bean public RedisTemplate&lt;String,String&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory)&#123; RedisTemplate&lt;String, String&gt; redisTemplate = new RedisTemplate&lt;String, String&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory); redisTemplate.afterPropertiesSet(); return redisTemplate; &#125; /** * Redis连接工厂 * @return */ @Bean public JedisConnectionFactory jedisConnectionFactory()&#123; JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory(); jedisConnectionFactory.afterPropertiesSet(); return jedisConnectionFactory; &#125;&#125; 使用多个缓存管理器 12345678910111213@Configuration@EnableCachingpublic class CompositeCacheConfig &#123; @Bean public CacheManager cacheManager()&#123; CompositeCacheManager cacheManager = new CompositeCacheManager(); ArrayList&lt;CacheManager&gt; managers = new ArrayList&lt;CacheManager&gt;(); managers.add(new JCacheCacheManager()); managers.add(new EhCacheCacheManager()); managers.add(new RedisCacheManager(new RedisTemplate())); cacheManager.setCacheManagers(managers); return cacheManager; &#125; 当查找缓存时，CompositeCacheManager会先检查jcache,接着ehcache,最后redis来查找缓存。 2.为方法添加注解以支持缓存 注解 描述 @Cacheable 适用于查询。 表明在调用方法之前，首先在缓存中查找方法的返回值，如果找到，则返回缓存的值。否则这个方法就会被调用，返回值放到缓存中。 @CachePut 适用于新增。表明将方法的返回值放到缓存中。调用前并不会检查缓存，方法始终会被调用。 @CacheEvict 适用于删除。表明在缓存中删除一个或多个条目。 @Caching 这是一个分组注解，能够同时应用多个其他的缓存注解。 以上注解都能运用在方法或类上。当将其放在单个方法上时，注解所描述的行为只会作用到这个方法上。如果放在类级别的话，那么缓存行为就会应用到这个类的所有方法上。 2.1填充缓存@Cacheable和CachePut的一些共有的属性。 属性 类型 描述 value String[] 要使用的缓存名称 condition String SpEl表达式，false不会将缓存应用到方法调用上 key String SpEl表达式，用来计算自定义的缓存key unless String SpEl表达式,true，返回值不会放到缓存中 Cacheable1234@Cacheable(\"userCache\")public User findOne(long id)&#123; return jdbc.queryById(id);&#125; 当findOne()被调用时，缓存切面会拦截调用并在缓存中查找，缓存的key是传递到findOne方法中的id参数。12@Cacheable(\"userCache\")public User findOne(long id); 当注解放在实现类时，作用只限于这个实现类，但如果放在接口的方法上，那么所有实现类都会应用相同的缓存规则 CachePut12@CachePut(\"userCache\")User save(User user); ++当save()方法被调用时，首先会保存user,然后返回的User会放到缓存中。那么问题来了，缓存的key默认是方法的参数即user,缓存的value是方法的返回值User。但是我们的查询方法是根据id作为key的。所以这里我们需要缓存的key也应该是User的id。因此我们需要自定义缓存的key.++ 自定义缓存key @Cacheable和@CachePut的key属性能替换掉默认的key，它是根据SpEL表达式计算得到的。常见的用法是定义的表达式与存储在缓存中的值有关。具体到我们上面的例子，需要将key设置为所保存的user的id,但参数中user还没保存，因此没有id，只能通过save()返回的保存后的user得到id。 Spring提供了多个用来定义缓存规则的SpEL扩展 表达式 描述 #root.args 传递给缓存方法的参数，形式为数组 #root.caches 该方法执行时所对应的缓存，形式为数组 #root.target 目标对象 #root.targetClass 目标对象的类，是#root.target.class的缩写 #root.method 缓存方法 #root.methodName 缓存方法的名字，是#root.method.name的缩写 #result 方法调用的返回值(不能用在@Cacheable注解上) #Argument 任意的方法参数名（如#argName）或参数索引（如#a0或#p0） 解决上面遇到的问题 12@CachePut(value=\"userCache\",key=\"#result.id\")User save(User user); 返回的User会保存在缓存中，key会返回的User的id属性。 条件化缓存 通过为方法添加Spring的缓存注解，Spring就会围绕这个方法创建一个缓存切面。但是有些场景下我们希望将缓存功能关闭。@Cacheable和@CachePut的属性unless和condition就可以做到。如果unless表达式计算为true，那么返回的数据就不会放到缓存中，只是禁止放缓存，依然会找缓存。如果condition表达式计算为false，那么对这个方法的缓存就会被禁掉，即既不会找也不会放缓存。 12@Cacheable(value=\"userCache\",unless=\"#result.message.contains('NoCache')\")User findOne(long id); 示例中为unless设置的SpEL表达式会表示检查返回的User对象的message属性，如果包含’NoCache’文本neirong,则这个表达式为true,所以这个返回值不会放到缓存中。否则如果为false,则这个返回值会被缓存。 12@Cacheable(value=\"userCache\",unless=\"#result.message.contains('NoCache')\",condition=\"#id&gt;=10\")User findOne(long id); 如果参数值id小于10，那么缓存就会被禁用，像没有加这个注解一样。 2.2移除缓存条目（@CacheEvict）12@CacheEvict(\"userCache\")void remove(long id); 当remove()方法调用时，会从缓存中删除一个条目。被删除条目的key与传递进来的id参数的值相等。与@Cacheable和@CachePut不同，@CacheEvict能够应用于返回值为void的方法上。 属性 类型 描述 value String[] 要使用的缓存名称 condition String SpEl表达式，false不会将缓存应用到方法调用上 key String SpEl表达式，用来计算自定义的缓存key allEntries boolean 如果为true，特定缓存的所有条目都会被移除 beforeInvocation boolean 如果为true,在方法调用之前移除条目，如果为fasle(默认)的话，在方法成功调用之后再移除条目","categories":[{"name":"spring","slug":"spring","permalink":"https://reasoncai.github.io/categories/spring/"}],"tags":[{"name":"spring","slug":"spring","permalink":"https://reasoncai.github.io/tags/spring/"},{"name":"缓存","slug":"缓存","permalink":"https://reasoncai.github.io/tags/缓存/"},{"name":"redis","slug":"redis","permalink":"https://reasoncai.github.io/tags/redis/"}]},{"title":"关于应用集群化部署的可行性分析","slug":"关于应用集群化部署的可行性分析","date":"2017-05-09T07:59:10.000Z","updated":"2017-05-09T08:26:56.000Z","comments":true,"path":"2017/05/09/关于应用集群化部署的可行性分析/","link":"","permalink":"https://reasoncai.github.io/2017/05/09/关于应用集群化部署的可行性分析/","excerpt":"","text":"1.问题背景Center经常在高峰期（一般在下午2点到5点）出现卡顿，请求堵塞在MQ的情况，严重影响业务和用户体验。 2.初步分析目前的部署架构如图所示：可以看出只有一个消费者（Center应用）在处理业务请求。在高峰期，处理速度远小于生产者将请求放入MQ的速度，导致请求在MQ中堆积，不能及时消费处理，结果就是系统响应缓慢，各种接口调用超时。 3.解决方案将Center集群化部署，提高消息的处理能力，并增强服务的高可用性。如图所示，目前先再部署多一个，后面根据业务的增长可以水平再扩展到N个。 4.解决方案的可行性分析Center可以轻松地水平扩展主要依赖于以下几点： 请求消息的无状态性 无状态服务(stateless service)指的是对单次请求的处理，不依赖其他请求，也就是说，处理一次请求所需的全部信息，要么都包含在这个请求里，要么可以从外部获取到（比如说数据库），服务器本身不存储任何信息 。 请求消息的无序性 无序性指的是请求消息不必按顺序依次消费处理。Center使用线程池来处理请求可以得出这个结论，因为每个线程获得CPU时间是随机的，所以对请求的处理是无序的。 其他 Center自身没有任何的定时任务需要执行，不用考虑定时任务重复执行的问题。 5.方案实施5.1单机多应用部署即拷贝多一份完整应用，并修改相关的脚本此方案的优点是简单，不用占用新服务器资源，IP没有变化，不用考虑外部接口对IP的限制问题。缺点是共用服务器资源，性能效果没有最优。 5.2多机部署在新的服务器上部署。此方案的优点是独占服务器资源，缺点是IP变化了，要考虑外部接口对IP限制的问题。 6.拓展：高可用部署考虑到业务的日益增长，当前的瓶颈是Center的处理速度,以后的瓶颈可能是Web服务器，MQ，数据库,网络等等，对此提供一份部署方案参考。","categories":[{"name":"架构","slug":"架构","permalink":"https://reasoncai.github.io/categories/架构/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://reasoncai.github.io/tags/并发/"},{"name":"高可用","slug":"高可用","permalink":"https://reasoncai.github.io/tags/高可用/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://reasoncai.github.io/tags/负载均衡/"},{"name":"集群","slug":"集群","permalink":"https://reasoncai.github.io/tags/集群/"}]},{"title":"npm install安装时忘记--save解决方法","slug":"npm-install安装时忘记-save解决方法","date":"2017-05-07T12:17:54.000Z","updated":"2017-05-09T08:09:01.000Z","comments":true,"path":"2017/05/07/npm-install安装时忘记-save解决方法/","link":"","permalink":"https://reasoncai.github.io/2017/05/07/npm-install安装时忘记-save解决方法/","excerpt":"","text":"网上还有一个解决方案就是：1npm install `ls node_modules` --save 或1npm install --save $(ls node_modules) 假如忘记保存的包太多，上面的方法都太麻烦了，直接npm init 重新生成package.json搞定。","categories":[],"tags":[{"name":"npm","slug":"npm","permalink":"https://reasoncai.github.io/tags/npm/"}]},{"title":"Java序列化小结","slug":"Java序列化小结","date":"2017-05-06T12:07:59.000Z","updated":"2017-05-28T15:51:15.000Z","comments":true,"path":"2017/05/06/Java序列化小结/","link":"","permalink":"https://reasoncai.github.io/2017/05/06/Java序列化小结/","excerpt":"","text":"Java序列化就是将一个对象转化成一串二进制表示的字节数组，通过保存或传递这些字节数据来带到持久化或通讯的目的。要序列化，对象必须实现java.io.Serializable接口。反序列化则是将这个字节数组再重新构造成对象，需要原始类作为模板，所以序列化的数据并不像class文件那样保存类的完整的结构信息。 12345FileOutPutStream fos = new FileOutPutStream(\"serv.dat\");ObjectOutputStream oos = new ObjectOutputStream(fos);SerialableObject object = new SerialableObject();oos.writeObject(object);oos.flush(); 当父类继承Serializable接口时，所有子类都可以被序列化。 子类实现了Serializable接口，父类没有，父类中的属性不能序列化（不报错，数据会丢失），但是在子类中属性仍能正确序列化。 如果序列化的属性是对象，则这个对象也必须实现Serializable接口，否则会报错。 在反序列化时，如果对象有属性的修改或删减，则修改的部分属性会丢失，但不会报错。 在反序列化时，如果serialVersionUID被修改，则反序列化会失败。 在纯java环境下，java序列化可以用。但个人认为还不如用fastjson序列化和反序列化（效率有人测试过比jdk序列化的高）。如果是多语言环境，尽量用通用的数据结构传递和保存信息，如json或者xml,也可以考虑其他序列化技术protobuf,thrift,avro等等。","categories":[{"name":"JAVA基础","slug":"JAVA基础","permalink":"https://reasoncai.github.io/categories/JAVA基础/"}],"tags":[{"name":"序列化","slug":"序列化","permalink":"https://reasoncai.github.io/tags/序列化/"}]},{"title":"Java并发编程的艺术读书笔记(2)-并发编程模型","slug":"Java并发编程的艺术读书笔记-2-并发编程模型","date":"2017-05-05T15:37:20.000Z","updated":"2017-05-06T06:11:10.000Z","comments":true,"path":"2017/05/05/Java并发编程的艺术读书笔记-2-并发编程模型/","link":"","permalink":"https://reasoncai.github.io/2017/05/05/Java并发编程的艺术读书笔记-2-并发编程模型/","excerpt":"","text":"1.并发编程模型的两个关键问题1.1线程之间如何通信。通信是指线程之间以何种机制来交换信息。有两种：共享内存和消息传递。在共享内存的并发模型里，线程之间共享程序的公共状态，通过读写内存中的公共状态进行隐式通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过发送消息来显示进行通信。java的并发采用的是共享内存模型。 1.2线程之间如何同步。同步是指程序中用于控制不同线程间操作发生相对顺序的机制。在共享内存并发模型中，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。 2.happens-before简介在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。这里提到的两个操作既可以是一个线程之内的，也可以是在不同线程之间的。两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行。happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。 2.1程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。2.2监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。2.3volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。2.4传递性：如果A happens-before B，且B happens-before C,那么A happens-before C。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://reasoncai.github.io/categories/读书笔记/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://reasoncai.github.io/tags/多线程/"},{"name":"并发","slug":"并发","permalink":"https://reasoncai.github.io/tags/并发/"}]},{"title":"Java并发编程的艺术读书笔记(1)-并发编程的挑战","slug":"Java并发编程的艺术读书笔记1-并发编程的挑战","date":"2017-05-03T15:28:45.000Z","updated":"2017-05-06T06:11:10.000Z","comments":true,"path":"2017/05/03/Java并发编程的艺术读书笔记1-并发编程的挑战/","link":"","permalink":"https://reasoncai.github.io/2017/05/03/Java并发编程的艺术读书笔记1-并发编程的挑战/","excerpt":"","text":"1.多线程不一定就比单线程快，因为线程有创建和上下文切换的开销。1.1vmstat测试上下文切换次数,Lmbench3测时长1.2如何减少上下文切换1.2.1无锁并发编程：多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID取模分段，不同的线程处理不同段的数据。1.2.2CAS算法：JDK的Atomic包使用CAS算法来更新数据，而不需要加锁。1.2.3使用最少线程：避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程处于等待状态。1.2.4使用协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。1.3查看线程信息1.3.1用jstack命令dump线程信息，看看pid为31177的进程里的线程都在做什么。1sudo -u admin /opt/ifeve/java/bin/jstack 31177 &gt; /home/dump17 1.3.2统计所有线程分别处于什么状态1grep java.lang.Thread.State dump17 | awk '&#123;print $2$3$4$5&#125;' | sort | uniq -c 2.死锁2.1避免死锁的几个常见方法2.1.1避免一个线程同时获取多个锁。2.1.2避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。2.1.3尝试使用定时锁，使用lock.tryLock(timeout)来替代使用内部锁机制。2.1.4对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。3.资源限制（硬件，软件）","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://reasoncai.github.io/categories/读书笔记/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://reasoncai.github.io/tags/多线程/"},{"name":"并发","slug":"并发","permalink":"https://reasoncai.github.io/tags/并发/"}]},{"title":"四层和七层负载均衡的区别","slug":"四层和七层负载均衡的区别","date":"2017-05-03T07:54:56.000Z","updated":"2017-05-06T06:11:10.000Z","comments":true,"path":"2017/05/03/四层和七层负载均衡的区别/","link":"","permalink":"https://reasoncai.github.io/2017/05/03/四层和七层负载均衡的区别/","excerpt":"负载均衡设备也常被称为”四到七层交换机”，那么四层和七层两者到底区别在哪里？","text":"负载均衡设备也常被称为”四到七层交换机”，那么四层和七层两者到底区别在哪里？ 第一，技术原理上的区别。 所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。 以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。 所谓七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。 以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。那么，为什么还需要七层负载均衡呢？ 第二，应用场景的需求。 七层应用负载的好处，是使得整个网络更”智能化”, 参考我们之前的另外一篇专门针对HTTP应用的优化的介绍，就可以基本上了解这种方式的优势所在。例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术；将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。当然这只是七层应用的一个小案例，从技术原理上，这种方式可以对客户端的请求和服务器的响应进行任意意义上的修改，极大的提升了应用系统在网络层的灵活性。很多在后台，(例如Nginx或者Apache)上部署的功能可以前移到负载均衡设备上，例如客户请求中的Header重写，服务器响应中的关键字过滤或者内容插入等功能。 另外一个常常被提到功能就是安全性。网络中最常见的SYN Flood攻击，即黑客控制众多源客户端，使用虚假IP地址对同一目标发送SYN攻击，通常这种攻击会大量发送SYN报文，耗尽服务器上的相关资源，以达到Denial of Service(DoS)的目的。从技术原理上也可以看出，四层模式下这些SYN攻击都会被转发到后端的服务器上；而七层模式下这些SYN攻击自然在负载均衡设备上就截止，不会影响后台服务器的正常运营。另外负载均衡设备可以在七层层面设定多种策略，过滤特定报文，例如SQL Injection等应用层面的特定攻击手段，从应用层面进一步提高系统整体安全。 现在的7层负载均衡，主要还是着重于应用广泛的HTTP协议，所以其应用范围主要是众多的网站或者内部信息平台等基于B/S开发的系统。 4层负载均衡则对应其他TCP应用，例如基于C/S开发的ERP等系统。 第三，七层应用需要考虑的问题。 1：是否真的必要，七层应用的确可以提高流量智能化，同时必不可免的带来设备配置复杂，负载均衡压力增高以及故障排查上的复杂性等问题。在设计系统时需要考虑四层七层同时应用的混杂情况。 2：是否真的可以提高安全性。例如SYN Flood攻击，七层模式的确将这些流量从服务器屏蔽，但负载均衡设备本身要有强大的抗DDoS能力，否则即使服务器正常而作为中枢调度的负载均衡设备故障也会导致整个应用的崩溃。 3：是否有足够的灵活度。七层应用的优势是可以让整个应用的流量智能化，但是负载均衡设备需要提供完善的七层功能，满足客户根据不同情况的基于应用的调度。最简单的一个考核就是能否取代后台Nginx或者Apache等服务器上的调度功能。能够提供一个七层应用开发接口的负载均衡设备，可以让客户根据需求任意设定功能，才真正有可能提供强大的灵活性和智能性。 转自：http://virtualadc.blog.51cto.com/3027116/591396","categories":[{"name":"转载","slug":"转载","permalink":"https://reasoncai.github.io/categories/转载/"}],"tags":[{"name":"负载均衡","slug":"负载均衡","permalink":"https://reasoncai.github.io/tags/负载均衡/"},{"name":"tcp/ip","slug":"tcp-ip","permalink":"https://reasoncai.github.io/tags/tcp-ip/"}]},{"title":"20170427","slug":"20170427","date":"2017-04-27T15:26:25.000Z","updated":"2017-05-06T06:11:10.000Z","comments":true,"path":"2017/04/27/20170427/","link":"","permalink":"https://reasoncai.github.io/2017/04/27/20170427/","excerpt":"1.mysql","text":"1.mysql 1.1登录mysql -uroot -proot1.2查看某个用户的登录地址权限12use mysql；SELECT User, Password, Host FROM user; 1.3授权允许任何主机使用“myuser”账号和“mypwd”密码连接到 MySQL 服务器。12mysql&gt; GRANT ALL PRIVILEGES ON *.* TO 'myuser'@'%' IDENTIFIED BY 'mypwd' WITH GRANT OPTION; mysql&gt; FLUSH PRIVILEGES; 2.linux指令2.1查看当前进程打开了多少个文件句柄1lsof -n |awk '&#123;print $2&#125;'|sort|uniq -c |sort -nr|more 123456789101112131415217 8246166 11412164 2540154 2557137 3838125 2296111 5212108 2865108 2864108 2161107 2811107 2551103 5128100 5127其中第一列为打开的文件句柄数量，第二行是进程号。通过进程号查看是哪个进程 1ps -ef | grep 8246 2.2设置系统最大允许打开文件句柄数量限制12ulimit -n 或 unlimit -a #查看系统文件打开数限制ulimit -n 2048 #设置open files数值方法这样就可以把当前用户的最大允许打开文件数量设置为2048了，但这种设置方法在重启后会还原为默认值。 永久设置方法1234vim /etc/security/limits.conf 在最后加入 * soft nofile 4096 * hard nofile 4096 最前的 * 表示所有用户，可根据需要设置某一用户，例如12root soft nofile 8192 root hard nofile 8192 改完后注销一下就能生效。 3.php-fpm配置今天wordpress发的新闻页面出现No input file specified 错误。 1还时好时坏，打开nginx日志发现too many open files错误，通过lsof -n |awk &apos;&#123;print $2&#125;&apos;|sort|uniq -c |sort -nr|more命令查询发现php-fpm占用了大量的文件句柄。将其关闭后重启问题得以暂时解决(实际应该要调整php-fpm的配置才能根本上解决问题)。 3.1nginx命令1234567891011121314151617181920212223nginx -s reload ：修改配置后重新加载生效nginx -s reopen ：重新打开日志文件nginx -t -c /path/to/nginx.conf 测试nginx配置文件是否正确关闭nginx：nginx -s stop :快速停止nginx quit ：完整有序的停止nginx其他的停止nginx 方式：ps -ef | grep nginxkill -QUIT 主进程号 ：从容停止Nginxkill -TERM 主进程号 ：快速停止Nginxpkill -9 nginx ：强制停止Nginx启动nginx:nginx -c /path/to/nginx.conf平滑重启nginx：kill -HUP 主进程号 3.2php-fpm命令123456789101112如果是编译的，可以在源码中复制php-fpm的init文件到系统中：cp -f sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm然后就可以使用以下命令启动、停止、重启和重新加载php-fpm了：service php-fpm startservice php-fpm restartservice php-fpm stopservice php-fpm reload极端关闭方法是killall php-fpm 3.3php-fpm配置(转自http://www.cnblogs.com/ahaii/p/5776809.html)在重启php-fpm时，恢复正常。1分钟之后又出现故障。查看php日志文件 /usr/local/php/var/log 后提示 WARNING: [pool www] server reached pm.max_children setting (5), consider raising it子进程数已经达到设置的最大值。 要设置php进程数量。需要在php-fpm.conf文件中修改。 先看/usr/local/php/etc/php-fpm.conf文件各项配置解析 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081pid = run/php-fpm.pid#pid设置，默认在安装目录中的var/run/php-fpm.pid，建议开启 error_log = log/php-fpm.log#错误日志，默认在安装目录中的var/log/php-fpm.log log_level = notice#错误级别. 可用级别为: alert（必须立即处理）, error（错误情况）, warning（警告情况）, notice（一般重要信息）, debug（调试信息）. 默认: notice. emergency_restart_threshold = 60emergency_restart_interval = 60s#表示在emergency_restart_interval所设值内出现SIGSEGV或者SIGBUS错误的php-cgi进程数如果超过 emergency_restart_threshold个，php-fpm就会优雅重启。这两个选项一般保持默认值。 process_control_timeout = 0#设置子进程接受主进程复用信号的超时时间. 可用单位: s(秒), m(分), h(小时), 或者 d(天) 默认单位: s(秒). 默认值: 0. daemonize = yes#后台执行fpm,默认值为yes，如果为了调试可以改为no。在FPM中，可以使用不同的设置来运行多个进程池。 这些设置可以针对每个进程池单独设置。 listen = 127.0.0.1:9000#fpm监听端口，即nginx中php处理的地址，一般默认值即可。可用格式为: ‘ip:port’, ‘port’, ‘/path/to/unix/socket’. 每个进程池都需要设置. listen.backlog = -1#backlog数，-1表示无限制，由操作系统决定，此行注释掉就行。backlog含义参考： http://www.3gyou.cc/?p=41 listen.allowed_clients = 127.0.0.1#允许访问FastCGI进程的IP，设置any为不限制IP，如果要设置其他主机的nginx也能访问这台FPM进程，listen处要设置成本地可被访问的IP。默认值是any。每个地址是用逗号分隔. 如果没有设置或者为空，则允许任何服务器请求连接 listen.owner = wwwlisten.group = wwwlisten.mode = 0666#unix socket设置选项，如果使用tcp方式访问，这里注释即可。 user = wwwgroup = www#启动进程的帐户和组 pm = dynamic #对于专用服务器，pm可以设置为static。#如何控制子进程，选项有static和dynamic。如果选择static，则由pm.max_children指定固定的子进程数。如果选择dynamic，则由下开参数决定：pm.max_children #，子进程最大数pm.start_servers #，启动时的进程数pm.min_spare_servers #，保证空闲进程数最小值，如果空闲进程小于此值，则创建新的子进程pm.max_spare_servers #，保证空闲进程数最大值，如果空闲进程大于此值，此进行清理 pm.max_requests = 1000#设置每个子进程重生之前服务的请求数. 对于可能存在内存泄漏的第三方模块来说是非常有用的. 如果设置为 ’0′ 则一直接受请求. 等同于 PHP_FCGI_MAX_REQUESTS 环境变量. 默认值: 0. pm.status_path = /status#FPM状态页面的网址. 如果没有设置, 则无法访问状态页面. 默认值: none. munin监控会使用到 ping.path = /ping#FPM监控页面的ping网址. 如果没有设置, 则无法访问ping页面. 该页面用于外部检测FPM是否存活并且可以响应请求. 请注意必须以斜线开头 (/)。 ping.response = pong#用于定义ping请求的返回相应. 返回为 HTTP 200 的 text/plain 格式文本. 默认值: pong. request_terminate_timeout = 0#设置单个请求的超时中止时间. 该选项可能会对php.ini设置中的’max_execution_time’因为某些特殊原因没有中止运行的脚本有用. 设置为 ’0′ 表示 ‘Off’.当经常出现502错误时可以尝试更改此选项。 request_slowlog_timeout = 10s#当一个请求该设置的超时时间后，就会将对应的PHP调用堆栈信息完整写入到慢日志中. 设置为 ’0′ 表示 ‘Off’ slowlog = log/$pool.log.slow#慢请求的记录日志,配合request_slowlog_timeout使用 rlimit_files = 1024#设置文件打开描述符的rlimit限制. 默认值: 系统定义值默认可打开句柄是1024，可使用 ulimit -n查看，ulimit -n 2048修改。 rlimit_core = 0#设置核心rlimit最大限制值. 可用值: ‘unlimited’ 、0或者正整数. 默认值: 系统定义值. chroot =#启动时的Chroot目录. 所定义的目录需要是绝对路径. 如果没有设置, 则chroot不被使用. chdir =#设置启动目录，启动时会自动Chdir到该目录. 所定义的目录需要是绝对路径. 默认值: 当前目录，或者/目录（chroot时） catch_workers_output = yes#重定向运行过程中的stdout和stderr到主要的错误日志文件中. 如果没有设置, stdout 和 stderr 将会根据FastCGI的规则被重定向到 /dev/null . 默认值: 空. 根据以上配置的解析，在php-fpm.conf文件中添加如下配置: 123456789pm.max_children = 100pm.start_servers = 30pm.min_spare_servers = 20pm.max_spare_servers = 100pm.max_requests = 500 以观后效。 另附豆瓣技术贴:https://www.douban.com/note/315222037/ 1、php-fpm优化参数介绍他们分别是：pm、pm.max_children、pm.start_servers、pm.min_spare_servers、pm.max_spare_servers。 pm：表示使用那种方式，有两个值可以选择，就是static（静态）或者dynamic（动态）。在更老一些的版本中，dynamic被称作apache-like。这个要注意看配置文件的说明。 下面4个参数的意思分别为： pm.max_children：静态方式下开启的php-fpm进程数量pm.start_servers：动态方式下的起始php-fpm进程数量pm.min_spare_servers：动态方式下的最小php-fpm进程数pm.max_spare_servers：动态方式下的最大php-fpm进程数量 区别： 如果dm设置为 static，那么其实只有pm.max_children这个参数生效。系统会开启设置数量的php-fpm进程。如果dm设置为 dynamic，那么pm.max_children参数失效，后面3个参数生效。系统会在php-fpm运行开始 的时候启动pm.start_servers个php-fpm进程，然后根据系统的需求动态在pm.min_spare_servers和pm.max_spare_servers之间调整php-fpm进程数 2、服务器具体配置对于我们的服务器，选择哪种执行方式比较好呢？事实上，跟Apache一样，运行的PHP程序在执行完成后，或多或少会有内存泄露的问题。这也是为什么开始的时候一个php-fpm进程只占用3M左右内存，运行一段时间后就会上升到20-30M的原因了。对于内存大的服务器（比如8G以上）来说，指定静态的max_children实际上更为妥当，因为这样不需要进行额外的进程数目控制，会提高效率。因为频繁开关php-fpm进程也会有时滞，所以内存够大的情况下开静态效果会更好。数量也可以根据 内存/30M 得到，比如8GB内存可以设置为100，那么php-fpm耗费的内存就能控制在 2G-3G的样子。如果内存稍微小点，比如1G，那么指定静态的进程数量更加有利于服务器的稳定。这样可以保证php-fpm只获取够用的内存，将不多的内存分配给其他应用去使用，会使系统的运行更加畅通。对于小内存的服务器来说，比如256M内存的VPS，即使按照一个20M的内存量来算，10个php-cgi进程就将耗掉200M内存，那系统的崩溃就应该很正常了。因此应该尽量地控制php-fpm进程的数量，大体明确其他应用占用的内存后，给它指定一个静态的小数量，会让系统更加平稳一些。或者使用动态方式，因为动态方式会结束掉多余的进程，可以回收释放一些内存，所以推荐在内存较少的服务器或VPS上使用。具体最大数量根据 内存/20M 得到。比如说512M的VPS，建议pm.max_spare_servers设置为20。至于pm.min_spare_servers，则建议根据服务器的负载情况来设置，比如服务器上只是部署php环境的话，比较合适的值在5~10之间。 本服务器配置 1、服务器基本信息：硬盘：数据盘30G、系统盘20G内存：1.5GCPU：双核系统：CentOS 6.3 64位带宽：独享2M2、部署的应用Git、SVN、Apache、Tomcat、PHP、Nginx、Mysql、JDK3、优化后的参数pm = dynamicpm.start_servers = 5pm.min_spare_servers = 2pm.max_spare_servers = 8 pm.max_requests = 500设置每个子进程重生之前服务的请求数. 对于可能存在内存泄漏的第三方模块来说是非常有用的. 如果设置为 ’0′ 则一直接受请求. 等同于 PHP_FCGI_MAX_REQUESTS 环境变量. 默认值: 0.这段配置的意思是，当一个 PHP-CGI 进程处理的请求数累积到 500 个后，自动重启该进程。 但是为什么要重启进程呢？ 一般在项目中，我们多多少少都会用到一些 PHP 的第三方库，这些第三方库经常存在内存泄漏问题，如果不定期重启 PHP-CGI 进程，势必造成内存使用量不断增长。因此 PHP-FPM 作为 PHP-CGI 的管理器，提供了这么一项监控功能，对请求达到指定次数的 PHP-CGI 进程进行重启，保证内存使用量不增长。 正是因为这个机制，在高并发的站点中，经常导致 502 错误，我猜测原因是 PHP-FPM 对从 NGINX 过来的请求队列没处理好。不过我目前用的还是 PHP 5.3.2，不知道在 PHP 5.3.3 中是否还存在这个问题。 目前我们的解决方法是，把这个值尽量设置大些，尽可能减少 PHP-CGI 重新 SPAWN 的次数，同时也能提高总体性能。在我们自己实际的生产环境中发现，内存泄漏并不明显，因此我们将这个值设置得非常大（204800）。大家要根据自己的实际情况设置这个值，不能盲目地加大。 ​ ​","categories":[{"name":"工作日记","slug":"工作日记","permalink":"https://reasoncai.github.io/categories/工作日记/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://reasoncai.github.io/tags/mysql/"},{"name":"nginx","slug":"nginx","permalink":"https://reasoncai.github.io/tags/nginx/"},{"name":"php","slug":"php","permalink":"https://reasoncai.github.io/tags/php/"},{"name":"linux","slug":"linux","permalink":"https://reasoncai.github.io/tags/linux/"}]},{"title":"Springboot中使用AOP统一处理Web请求日志","slug":"Springboot中使用AOP统一处理Web请求日志","date":"2017-04-26T08:30:48.000Z","updated":"2017-05-06T06:11:10.000Z","comments":true,"path":"2017/04/26/Springboot中使用AOP统一处理Web请求日志/","link":"","permalink":"https://reasoncai.github.io/2017/04/26/Springboot中使用AOP统一处理Web请求日志/","excerpt":"AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是Spring框架中的一个重要内容，它通过对既有程序定义一个切入点，然后在其前后切入不同的执行内容，比如常见的有：打开数据库连接/关闭数据库连接、打开事务/关闭事务、记录日志等。基于AOP不会破坏原来程序逻辑，因此它可以很好的对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。","text":"AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是Spring框架中的一个重要内容，它通过对既有程序定义一个切入点，然后在其前后切入不同的执行内容，比如常见的有：打开数据库连接/关闭数据库连接、打开事务/关闭事务、记录日志等。基于AOP不会破坏原来程序逻辑，因此它可以很好的对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。下面主要讲两个内容，一个是如何在Spring Boot中引入Aop功能，二是如何使用Aop做切面去统一处理Web请求的日志。 以下所有操作基于chapter4-2-2工程进行。 准备工作因为需要对web请求做切面来记录日志，所以先引入web模块，并创建一个简单的hello请求的处理。 pom.xml中引入web模块 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 实现一个简单请求处理：通过传入name参数，返回“hello xxx”的功能。 12345678910@RestControllerpublic class HelloController &#123; @RequestMapping(value = \"/hello\", method = RequestMethod.GET) @ResponseBody public String hello(@RequestParam String name) &#123; return \"Hello \" + name; &#125;&#125; 下面，我们可以对上面的/hello请求，进行切面日志记录。 引入AOP依赖在Spring Boot中引入AOP就跟引入其他模块一样，非常简单，只需要在pom.xml中加入如下依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt; 在完成了引入AOP依赖包后，一般来说并不需要去做其他配置。也许在Spring中使用过注解配置方式的人会问是否需要在程序主类中增加@EnableAspectJAutoProxy来启用，实际并不需要。 可以看下面关于AOP的默认配置属性，其中spring.aop.auto属性默认是开启的，也就是说只要引入了AOP依赖后，默认已经增加了@EnableAspectJAutoProxy。 1234# AOPspring.aop.auto=true # Add @EnableAspectJAutoProxy.spring.aop.proxy-target-class=false # Whether subclass-based (CGLIB) proxies are to be created (true) as opposed to standard Java interface-based proxies (false). 而当我们需要使用CGLIB来实现AOP的时候，需要配置spring.aop.proxy-target-class=true，不然默认使用的是标准Java的实现。 实现Web层的日志切面实现AOP的切面主要有以下几个要素： 使用@Aspect注解将一个java类定义为切面类 使用@Pointcut定义一个切入点，可以是一个规则表达式，比如下例中某个package下的所有函数，也可以是一个注解等。 根据需要在切入点不同位置的切入内容 使用@Before在切入点开始处切入内容 使用@After在切入点结尾处切入内容 使用@AfterReturning在切入点return内容之后切入内容（可以用来对处理返回值做一些加工处理） 使用@Around在切入点前后切入内容，并自己控制何时执行切入点自身的内容 使用@AfterThrowing用来处理当切入内容部分抛出异常之后的处理逻辑 12345678910111213141516171819202122232425262728293031@Aspect@Componentpublic class WebLogAspect &#123; private Logger logger = Logger.getLogger(getClass()); @Pointcut(\"execution(public * com.didispace.web..*.*(..))\") public void webLog()&#123;&#125; @Before(\"webLog()\") public void doBefore(JoinPoint joinPoint) throws Throwable &#123; // 接收到请求，记录请求内容 ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); // 记录下请求内容 logger.info(\"URL : \" + request.getRequestURL().toString()); logger.info(\"HTTP_METHOD : \" + request.getMethod()); logger.info(\"IP : \" + request.getRemoteAddr()); logger.info(\"CLASS_METHOD : \" + joinPoint.getSignature().getDeclaringTypeName() + \".\" + joinPoint.getSignature().getName()); logger.info(\"ARGS : \" + Arrays.toString(joinPoint.getArgs())); &#125; @AfterReturning(returning = \"ret\", pointcut = \"webLog()\") public void doAfterReturning(Object ret) throws Throwable &#123; // 处理完请求，返回内容 logger.info(\"RESPONSE : \" + ret); &#125;&#125; 可以看上面的例子，通过@Pointcut定义的切入点为com.didispace.web包下的所有函数（对web层所有请求处理做切入点），然后通过@Before实现，对请求内容的日志记录（本文只是说明过程，可以根据需要调整内容），最后通过@AfterReturning记录请求返回的对象。 通过运行程序并访问：http://localhost:8080/hello?name=didi，可以获得下面的日志输出 1234562016-05-19 13:42:13,156 INFO WebLogAspect:41 - URL : http://localhost:8080/hello2016-05-19 13:42:13,156 INFO WebLogAspect:42 - HTTP_METHOD : http://localhost:8080/hello2016-05-19 13:42:13,157 INFO WebLogAspect:43 - IP : 0:0:0:0:0:0:0:12016-05-19 13:42:13,160 INFO WebLogAspect:44 - CLASS_METHOD : com.didispace.web.HelloController.hello2016-05-19 13:42:13,160 INFO WebLogAspect:45 - ARGS : [didi]2016-05-19 13:42:13,170 INFO WebLogAspect:52 - RESPONSE:Hello didi 优化：AOP切面中的同步问题在WebLogAspect切面中，分别通过doBefore和doAfterReturning两个独立函数实现了切点头部和切点返回后执行的内容，若我们想统计请求的处理时间，就需要在doBefore处记录时间，并在doAfterReturning处通过当前时间与开始处记录的时间计算得到请求处理的消耗时间。 那么我们是否可以在WebLogAspect切面中定义一个成员变量来给doBefore和doAfterReturning一起访问呢？是否会有同步问题呢？ 的确，直接在这里定义基本类型会有同步问题，所以我们可以引入ThreadLocal对象，像下面这样进行记录： 123456789101112131415161718192021222324252627@Aspect@Componentpublic class WebLogAspect &#123; private Logger logger = Logger.getLogger(getClass()); ThreadLocal&lt;Long&gt; startTime = new ThreadLocal&lt;&gt;(); @Pointcut(\"execution(public * com.didispace.web..*.*(..))\") public void webLog()&#123;&#125; @Before(\"webLog()\") public void doBefore(JoinPoint joinPoint) throws Throwable &#123; startTime.set(System.currentTimeMillis()); // 省略日志记录内容 &#125; @AfterReturning(returning = \"ret\", pointcut = \"webLog()\") public void doAfterReturning(Object ret) throws Throwable &#123; // 处理完请求，返回内容 logger.info(\"RESPONSE : \" + ret); logger.info(\"SPEND TIME : \" + (System.currentTimeMillis() - startTime.get())); &#125;&#125; 优化：AOP切面的优先级由于通过AOP实现，程序得到了很好的解耦，但是也会带来一些问题，比如：我们可能会对Web层做多个切面，校验用户，校验头信息等等，这个时候经常会碰到切面的处理顺序问题。 所以，我们需要定义每个切面的优先级，我们需要@Order(i)注解来标识切面的优先级。i的值越小，优先级越高。假设我们还有一个切面是CheckNameAspect用来校验name必须为didi，我们为其设置@Order(10)，而上文中WebLogAspect设置为@Order(5)，所以WebLogAspect有更高的优先级，这个时候执行顺序是这样的： 在@Before中优先执行@Order(5)的内容，再执行@Order(10)的内容 在@After和@AfterReturning中优先执行@Order(10)的内容，再执行@Order(5)的内容 所以我们可以这样子总结： 在切入点前的操作，按order的值由小到大执行 在切入点后的操作，按order的值由大到小执行 本文转自http://blog.didispace.com/springbootaoplog/","categories":[{"name":"转载","slug":"转载","permalink":"https://reasoncai.github.io/categories/转载/"},{"name":"Spring Boot","slug":"转载/Spring-Boot","permalink":"https://reasoncai.github.io/categories/转载/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://reasoncai.github.io/tags/Spring-Boot/"},{"name":"AOP","slug":"AOP","permalink":"https://reasoncai.github.io/tags/AOP/"}]},{"title":"100亿数据平滑数据迁移,不影响服务","slug":"100亿数据平滑数据迁移-不影响服务","date":"2017-04-25T16:13:44.000Z","updated":"2017-05-06T06:11:10.000Z","comments":true,"path":"2017/04/26/100亿数据平滑数据迁移-不影响服务/","link":"","permalink":"https://reasoncai.github.io/2017/04/26/100亿数据平滑数据迁移-不影响服务/","excerpt":"100亿数据平滑数据迁移,不影响服务","text":"100亿数据平滑数据迁移,不影响服务 2017-03-23 58沈剑 架构师之路 一、问题的提出 互联网有很多“数据量较大，并发量较大，业务复杂度较高”的业务场景，其典型系统分层架构如下：（1）上游是业务层biz，实现个性化的业务逻辑 （2）中游是服务层service，封装数据访问 （3）下游是数据层db，存储固化的业务数据 服务化分层架构的好处是，服务层屏蔽下游数据层的复杂性，例如缓存、分库分表、存储引擎等存储细节不需要向调用方暴露，而只向上游提供方便的RPC访问接口，当有一些数据层变化的时候，所有的调用方也不需要升级，只需要服务层升级即可。 互联网架构，很多时候面临着这样一些需求： 需求1-&gt;底层表结构变更：数据量非常大的情况下，数据表增加了一些属性，删除了一些属性，修改了一些属性。 需求2-&gt;分库个数变换：由于数据量的持续增加，底层分库个数非成倍增加。 需求3-&gt;底层存储介质变换：底层存储引擎由一个数据库换为另一个数据库。 种种需求，都需要进行数据迁移，如何平滑迁移数据，迁移过程不停机，保证系统持续服务，是文本将要讨论的问题。 二、停机方案 在讨论平滑迁移数据方案之前，先看下不平滑的停机数据迁移方案，主要分三个步骤。 步骤一：挂一个类似“为了给广大用户提供更好的服务，服务器会在凌晨0:00-0:400进行停机维护”的公告，并在对应时段进行停机，这个时段系统没有流量进入。 步骤二：停机后，研发一个离线的数据迁移工具，进行数据迁移。针对第一节的三类需求，会分别开发不同的数据迁移工具。 （1）底层表结构变更需求：开发旧表导新表的工具 （2）分库个数变换需求：开发2库导3库的工具 （3）底层存储介质变换需求：开发Mongo导Mysql工具 步骤三：恢复服务，并将流量切到新库，不同的需求，可能会涉及不同服务升级。 （1）底层表结构变更需求：服务要升级到访问新表 （2）分库个数变换需求：服务不需要升级，只需要改寻库路由配置 （3）底层存储介质变换需求：服务升级到访问新的存储介质 总的来说，停机方案是相对直观和简单的，但对服务的可用性有影响，许多游戏公司的服务器升级，游戏分区与合区，可能会采用类似的方案。 除了影响服务的可用性，这个方案还有一个缺点，就是必须在指定时间完成升级，这个对研发、测试、运维同学来说，压力会非常大，一旦出现问题例如数据不一致，必须在规定时间内解决，否则只能回滚。根据经验，人压力越大越容易出错，这个缺点一定程度上是致命的。 无论如何，停机方案并不是今天要讨论的重点，接下来看一下常见的平滑数据迁移方案。 三、平滑迁移-追日志法 平滑迁移方案一，追日志法，这个方案主要分为五个步骤。 数据迁移前，上游业务应用通过旧的服务访问旧的数据。 步骤一：服务进行升级，记录“对旧库上的数据修改”的日志（这里的修改，为数据的insert, delete, update），这个日志不需要记录详细数据，主要记录： （1）被修改的库 （2）被修改的表 （3）被修改的唯一主键 具体新增了什么行，修改后的数据格式是什么，不需要详细记录。这样的好处是，不管业务细节如何变化，日志的格式是固定的，这样能保证方案的通用性。 这个服务升级风险较小：（1）写接口是少数接口，改动点较少（2）升级只是增加了一些日志，对业务功能没有任何影响 步骤二：研发一个数据迁移工具，进行数据迁移。这个数据迁移工具和离线迁移工具一样，把旧库中的数据转移到新库中来。 这个小工具的风险较小： （1）整个过程依然是旧库对线上提供服务（2）小工具的复杂度较低（3）任何时间发现问题，都可以把新库中的数据干掉重来（4）可以限速慢慢迁移，技术同学没有时间压力 数据迁移完成之后，就能够切到新库提供服务了么？ 答案是否定的，在数据迁移的过程中，旧库依然对线上提供着服务，库中的数据随时可能变化，这个变化并没有反映到新库中来，于是旧库和新库的数据并不一致，所以不能直接切库，需要将数据追平。 哪些数据发生了变化呢？ 步骤一中日志里记录的不就是么？ 步骤三：研发一个读取日志并迁移数据的小工具，要把步骤二迁移数据过程中产生的差异数据追平。这个小工具需要做的是： （1）读取日志，得到哪个库、哪个表、哪个主键发生了变化 （2）把旧库中对应主键的记录读取出来 （3）把新库中对应主键的记录替换掉 无论如何，原则是数据以旧库为准。 这个小工具的风险也很小： （1）整个过程依然是旧库对线上提供服务 （2）小工具的复杂度较低 （3）任何时间发现问题，大不了从步骤二开始重来 （4）可以限速慢慢重放日志，技术同学没有时间压力 日志重放之后，就能够切到新库提供服务了么？ 答案依然是否定的，在日志重放的过程中，旧库中又可能有数据发生了变化，导致数据不一致，所以还是不能切库，需要进一步读取日志，追平记录。可以看到，重放日志追平数据的程序是一个while(1)的程序，新库与旧库中的数据追平也会是一个“无限逼近”的过程。 什么时候数据会完全一致呢？ 步骤四：在持续重放日志，追平数据的过程中，研发一个数据校验的小工具，将旧库和新库中的数据进行比对，直到数据完全一致。 这个小工具的风险依旧很小： （1）整个过程依然是旧库对线上提供服务 （2）小工具的复杂度较低 （3）任何时间发现问题，大不了从步骤二开始重来 （4）可以限速慢慢比对数据，技术同学没有时间压力 步骤五：在数据比对完全一致之后，将流量迁移到新库，新库提供服务，完成迁移。 如果步骤四数据一直是99.9%的一致，不能完全一致，也是正常的，可以做一个秒级的旧库readonly，等日志重放程序完全追上数据后，再进行切库切流量。 至此，升级完毕，整个过程能够持续对线上提供服务，不影响服务的可用性。 四、平滑迁移-双写法 平滑迁移方案二，双写法，这个方案主要分为四个步骤。 数据迁移前，上游业务应用通过旧的服务访问旧的数据。 步骤一：服务进行升级，对“对旧库上的数据修改”（这里的修改，为数据的insert, delete, update），在新库上进行相同的修改操作，这就是所谓的“双写”，主要修改操作包括： （1）旧库与新库的同时insert （2）旧库与新库的同时delete （3）旧库与新库的同时update 由于新库中此时是没有数据的，所以双写旧库与新库中的affect rows可能不一样，不过这完全不影响业务功能，只要不切库，依然是旧库提供业务服务。 这个服务升级风险较小： （1）写接口是少数接口，改动点较少 （2）新库的写操作执行成功与否，对业务功能没有任何影响 步骤二：研发一个数据迁移工具，进行数据迁移。这个数据迁移工具在本文中已经出现第三次了，把旧库中的数据转移到新库中来。 这个小工具的风险较小： （1）整个过程依然是旧库对线上提供服务 （2）小工具的复杂度较低 （3）任何时间发现问题，都可以把新库中的数据干掉重来 （4）可以限速慢慢迁移，技术同学没有时间压力 数据迁移完成之后，就能够切到新库提供服务了么？ 答案是肯定的，因为前置步骤进行了双写，所以理论上数据迁移完之后，新库与旧库的数据应该完全一致。 由于迁移数据的过程中，旧库新库双写操作在同时进行，怎么证明数据迁移完成之后数据就完全一致了呢？ 如上图所示： （1）左侧是旧库中的数据，右侧是新库中的数据 （2）按照primary key从min到max的顺序，分段，限速进行数据的迁移，假设已经迁移到now这个数据段 数据迁移过程中的修改操作分别讨论： （1）假设迁移过程中进行了一个双insert操作，旧库新库都插入了数据，数据一致性没有被破坏 （2）假设迁移过程中进行了一个双delete操作，这又分为两种情况 （2.1）假设这delete的数据属于[min,now]范围，即已经完成迁移，则旧库新库都删除了数据，数据一致性没有被破坏 （2.2）假设这delete的数据属于[now,max]范围，即未完成迁移，则旧库中删除操作的affect rows为1，新库中删除操作的affect rows为0，但是数据迁移工具在后续数据迁移中，并不会将这条旧库中被删除的数据迁移到新库中，所以数据一致性仍没有被破坏 （3）假设迁移过程中进行了一个双update操作，可以认为update操作是一个delete加一个insert操作的复合操作，所以数据仍然是一致的 除非除非除非，在一种非常非常非常极限的情况下： （1）date-migrate-tool刚好从旧库中将某一条数据X取出 （2）在X插入到新库中之前，旧库与新库中刚好对X进行了双delete操作 （3）date-migrate-tool再将X插入到新库中 这样，会出现新库比旧库多出一条数据X。 但无论如何，为了保证数据的一致性，切库之前，还是需要进行数据校验的。 步骤三：在数据迁移完成之后，需要使用数据校验的小工具，将旧库和新库中的数据进行比对，完全一致则符合预期，如果出现步骤二中的极限不一致情况，则以旧库中的数据为准。 这个小工具的风险依旧很小： （1）整个过程依然是旧库对线上提供服务 （2）小工具的复杂度较低 （3）任何时间发现问题，大不了从步骤二开始重来 （4）可以限速慢慢比对数据，技术同学没有时间压力 步骤四：数据完全一致之后，将流量切到新库，完成平滑数据迁移。 至此，升级完毕，整个过程能够持续对线上提供服务，不影响服务的可用性。 五、总结 针对互联网很多“数据量较大，并发量较大，业务复杂度较高”的业务场景，在 （1）底层表结构变更 （2）分库个数变换 （3）底层存储介质变换 的众多需求下，需要进行数据迁移，完成“平滑迁移数据，迁移过程不停机，保证系统持续服务”有两种常见的解决方案。 追日志法，五个步骤： （1）服务进行升级，记录“对旧库上的数据修改”的日志 （2）研发一个数据迁移小工具，进行数据迁移 （3）研发一个读取日志小工具，追平数据差异 （4）研发一个数据比对小工具，校验数据一致性 （5）流量切到新库，完成平滑迁移 双写法，四个步骤： （1）服务进行升级，记录“对旧库上的数据修改”进行新库的双写 （2）研发一个数据迁移小工具，进行数据迁移 （3）研发一个数据比对小工具，校验数据一致性 （4）流量切到新库，完成平滑迁移","categories":[{"name":"转载","slug":"转载","permalink":"https://reasoncai.github.io/categories/转载/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://reasoncai.github.io/tags/数据库/"}]},{"title":"logback使用配置详解","slug":"logback使用配置详解","date":"2017-04-25T08:42:49.000Z","updated":"2017-05-06T06:11:10.000Z","comments":true,"path":"2017/04/25/logback使用配置详解/","link":"","permalink":"https://reasoncai.github.io/2017/04/25/logback使用配置详解/","excerpt":"1.介绍 Logback是由log4j创始人设计的另一个开源日志组件,它当前分为下面下个模块：","text":"1.介绍 Logback是由log4j创始人设计的另一个开源日志组件,它当前分为下面下个模块： logback-core：其它两个模块的基础模块 logback-classic：它是log4j的一个改良版本，同时它完整实现了slf4j API使你可以很方便地更换成其它日志系统如log4j或JDK14 Logging logback-access：访问模块与Servlet容器集成提供通过Http来访问日志的功能（非必须的包） 注意：还要一个slf4j的包 2.配置介绍2.1Logger、appender及layoutLogger作为日志的记录器，把它关联到应用的对应的context上后，主要用于存放日志对象，也可以定义日志类型、级别。Appender主要用于指定日志输出的目的地，目的地可以是控制台、文件、远程套接字服务器、 MySQL、PostreSQL、 Oracle和其他数据库、 JMS和远程UNIX Syslog守护进程等。Layout 负责把事件转换成字符串，格式化的日志信息的输出。 2.2logger context各个logger 都被关联到一个 LoggerContext，LoggerContext负责制造logger，也负责以树结构排列各logger。其他所有logger也通过org.slf4j.LoggerFactory 类的静态方法getLogger取得。 getLogger方法以 logger名称为参数。用同一名字调用LoggerFactory.getLogger 方法所得到的永远都是同一个logger对象的引用。 2.3有效级别及级别的继承Logger 可以被分配级别。级别包括：TRACE、DEBUG、INFO、WARN 和 ERROR，定义于ch.qos.logback.classic.Level类。如果 logger没有被分配级别，那么它将从有被分配级别的最近的祖先那里继承级别。root logger 默认级别是 DEBUG。 2.4打印方法与基本的选择规则打印方法决定记录请求的级别。例如，如果 L 是一个 logger 实例，那么，语句 L.info(“..”)是一条级别为 INFO的记录语句。记录请求的级别在高于或等于其 logger 的有效级别时被称为被启用，否则，称为被禁用。记录请求级别为 p，其 logger的有效级别为 q，只有则当 p&gt;=q时，该请求才会被执行。该规则是 logback 的核心。级别排序为： TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR 3.logback的默认配置如果配置文件 logback-test.xml 和 logback.xml 都不存在，那么 logback 默认地会调用BasicConfigurator ，创建一个最小化配置。最小化配置由一个关联到根 logger 的ConsoleAppender 组成。输出用模式为%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n 的 PatternLayoutEncoder 进行格式化。root logger 默认级别是 DEBUG。 3.1Logback的配置文件Logback 配置文件的语法非常灵活。正因为灵活，所以无法用 DTD 或 XML schema 进行定义。尽管如此，可以这样描述配置文件的基本结构：以开头，后面有零个或多个元素，有零个或多个元素，有最多一个元素。 3.2Logback默认配置的步骤 1. JVM参数指定 -Dlogback.configurationFile=D:\\PSS\\PssCenter\\config\\logback.xml 2. 尝试在 classpath下查找文件logback-test.xml； 3. 如果文件不存在，则查找文件logback.xml； 4. 如果两个文件都不存在，logback用BasicConfigurator自动对自己进行配置，这会导致记录输出到控制台。 4.logback.xml常用配置详解 4.1根节点configuration，包含下面三个属性： scan: 当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。 scanPeriod: 设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 debug: 当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 例如：123&lt;configuration scan=\"true\" scanPeriod=\"60 seconds\" debug=\"false\"&gt; &lt;!--其他配置省略--&gt; &lt;/configuration&gt; 4.2子节点contextName：用来设置上下文名称，每个logger都关联到logger上下文，默认上下文名称为default。但可以使用设置成其他名字，用于区分不同应用程序的记录。一旦设置，不能修改。 例如：1234&lt;configuration scan=\"true\" scanPeriod=\"60 seconds\" debug=\"false\"&gt; &lt;contextName&gt;myAppName&lt;/contextName&gt; &lt;!--其他配置省略--&gt;&lt;/configuration&gt; 4.3子节点property：用来定义变量值，它有两个属性name和value，通过property定义的值会被插入到logger上下文中，可以使“${}”来使用变量。 name: 变量的名称 value: 的值时变量定义的值 例如：12345&lt;configuration scan=\"true\" scanPeriod=\"60 seconds\" debug=\"false\"&gt; &lt;property name=\"APP_Name\" value=\"myAppName\" /&gt; &lt;contextName&gt;$&#123;APP_Name&#125;&lt;/contextName&gt; &lt;!--其他配置省略--&gt; &lt;/configuration&gt; 4.4子节点timestamp：获取时间戳字符串，他有两个属性key和datePattern key: 标识此timestamp的名字； datePattern: 设置将当前时间（解析配置文件的时间）转换为字符串的模式，遵循java.txt.SimpleDateFormat的格式。 例如：12345&lt;configuration scan=\"true\" scanPeriod=\"60 seconds\" debug=\"false\"&gt; &lt;timestamp key=\"bySecond\" datePattern=\"yyyyMMdd'T'HHmmss\"/&gt; &lt;contextName&gt;$&#123;bySecond&#125;&lt;/contextName&gt; &lt;!-- 其他配置省略--&gt; &lt;/configuration&gt; 4.5子节点appender：负责写日志的组件，它有两个必要属性name和class。name指定appender名称，class指定appender的全限定名4.5.1ConsoleAppender 把日志输出到控制台，有以下子节点： encoder：对日志进行格式化。（具体参数稍后讲解 ） target：字符串System.out(默认)或者System.err（区别不多说了） 例如：12345678910&lt;configuration&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg %n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=\"DEBUG\"&gt; &lt;appender-ref ref=\"STDOUT\" /&gt; &lt;/root&gt; &lt;/configuration&gt; 上述配置表示把&gt;=DEBUG级别的日志都输出到控制台 4.5.2FileAppender：把日志添加到文件，有以下子节点： file：被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。 append：如果是 true，日志被追加到文件结尾，如果是 false，清空现存文件，默认是true。 encoder：对记录事件进行格式化。（具体参数稍后讲解 ） prudent：如果是 true，日志会被安全的写入文件，即使其他的FileAppender也在向此文件做写入操作，效率低，默认是 false。 例如：12345678910111213 &lt;configuration&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"&gt; &lt;file&gt;testFile.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=\"DEBUG\"&gt; &lt;appender-ref ref=\"FILE\" /&gt; &lt;/root&gt; &lt;/configuration&gt; 上述配置表示把&gt;=DEBUG级别的日志都输出到testFile.log 4.5.3RollingFileAppender：滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件。有以下子节点： file：被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。 append：如果是 true，日志被追加到文件结尾，如果是 false，清空现存文件，默认是true。 rollingPolicy:当发生滚动时，决定RollingFileAppender的行为，涉及文件移动和重命名。属性class定义具体的滚动策略类 class=”ch.qos.logback.core.rolling.TimeBasedRollingPolicy”： 最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动。有以下子节点： fileNamePattern：必要节点，包含文件名及“%d”转换符，“%d”可以包含一个java.text.SimpleDateFormat指定的时间格式，如：%d{yyyy-MM}。如果直接使用 %d，默认格式是 yyyy-MM-dd。RollingFileAppender的file字节点可有可无，通过设置file，可以为活动文件和归档文件指定不同位置，当前日志总是记录到file指定的文件（活动文件），活动文件的名字不会改变；如果没设置file，活动文件的名字会根据fileNamePattern 的值，每隔一段时间改变一次。“/”或者“\\”会被当做目录分隔符。 maxHistory:可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每个月滚动，且maxHistory是6，则只保存最近6个月的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除。 class=”ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy”： 查看当前活动文件的大小，如果超过指定大小会告知RollingFileAppender 触发当前活动文件滚动。只有一个节点: maxFileSize:这是活动文件的大小，默认值是10MB。 prudent：当为true时，不支持FixedWindowRollingPolicy。支持TimeBasedRollingPolicy，但是有两个限制，1不支持也不允许文件压缩，2不能设置file属性，必须留空。 triggeringPolicy : 告知 RollingFileAppender 合适激活滚动。 class=”ch.qos.logback.core.rolling.FixedWindowRollingPolicy” 根据固定窗口算法重命名文件的滚动策略。有以下子节点： minIndex:窗口索引最小值 maxIndex:窗口索引最大值，当用户指定的窗口过大时，会自动将窗口设置为12。 fileNamePattern:必须包含“%i”例如，假设最小值和最大值分别为1和2，命名模式为 mylog%i.log,会产生归档文件mylog1.log和mylog2.log。还可以指定文件压缩选项，例如，mylog%i.log.gz 或者 没有log%i.log.zip 例如：123456789101112131415&lt;configuration&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;logFile.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=\"DEBUG\"&gt; &lt;appender-ref ref=\"FILE\" /&gt; &lt;/root&gt; &lt;/configuration&gt; 上述配置表示每天生成一个日志文件，保存30天的日志文件。12345678910111213141516171819202122 &lt;configuration&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;test.log&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.FixedWindowRollingPolicy\"&gt; &lt;fileNamePattern&gt;tests.%i.log.zip&lt;/fileNamePattern&gt; &lt;minIndex&gt;1&lt;/minIndex&gt; &lt;maxIndex&gt;3&lt;/maxIndex&gt; &lt;/rollingPolicy&gt; &lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt; &lt;maxFileSize&gt;5MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%-4relative [%thread] %-5level %logger&#123;35&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=\"DEBUG\"&gt; &lt;appender-ref ref=\"FILE\" /&gt; &lt;/root&gt; &lt;/configuration&gt; 上述配置表示按照固定窗口模式生成日志文件，当文件大于20MB时，生成新的日志文件。窗口大小是1到3，当保存了3个归档文件后，将覆盖最早的日志。 encoder：对记录事件进行格式化。负责两件事，一是把日志信息转换成字节数组，二是把字节数组写入到输出流。PatternLayoutEncoder 是唯一有用的且默认的encoder ，有一个pattern节点，用来设置日志的输入格式。使用“%”加“转换符”方式，如果要输出“%”，则必须用“\\”对“\\%”进行转义。 4.5.4还有SocketAppender、SMTPAppender、DBAppender、SyslogAppender、SiftingAppender，并不常用，这里就不详解了。大家可以参考官方文档http://logback.qos.ch/documentation.html，还可以编写自己的Appender。 4.6、子节点loger：用来设置某一个包或具体的某一个类的日志打印级别、以及指定appender。loger仅有一个name属性，一个可选的level和一个可选的addtivity属性。可以包含零个或多个appender-ref元素，标识这个appender将会添加到这个loger name: 用来指定受此loger约束的某一个包或者具体的某一个类。 level: 用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL和OFF，还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。 如果未设置此属性，那么当前loger将会继承上级的级别。addtivity: 是否向上级loger传递打印信息。默认是true。同loger一样，可以包含零个或多个appender-ref元素，标识这个appender将会添加到这个loger。 4.7、子节点root:它也是loger元素，但是它是根loger,是所有loger的上级。只有一个level属性，因为name已经被命名为”root”,且已经是最上级了。 level: 用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL和OFF，不能设置为INHERITED或者同义词NULL。 默认是DEBUG。 5.常用logger配置123456789101112&lt;!-- show parameters for hibernate sql 专为 Hibernate 定制 --&gt;&lt;logger name=\"org.hibernate.type.descriptor.sql.BasicBinder\" level=\"TRACE\" /&gt;&lt;logger name=\"org.hibernate.type.descriptor.sql.BasicExtractor\" level=\"DEBUG\" /&gt;&lt;logger name=\"org.hibernate.SQL\" level=\"DEBUG\" /&gt;&lt;logger name=\"org.hibernate.engine.QueryParameters\" level=\"DEBUG\" /&gt;&lt;logger name=\"org.hibernate.engine.query.HQLQueryPlan\" level=\"DEBUG\" /&gt;&lt;!--myibatis log configure--&gt;&lt;logger name=\"com.apache.ibatis\" level=\"TRACE\"/&gt;&lt;logger name=\"java.sql.Connection\" level=\"DEBUG\"/&gt;&lt;logger name=\"java.sql.Statement\" level=\"DEBUG\"/&gt;&lt;logger name=\"java.sql.PreparedStatement\" level=\"DEBUG\"/&gt; 6.Demo 1、添加依赖包logback使用需要和slf4j一起使用，所以总共需要添加依赖的包有slf4j-apilogback使用需要和slf4j一起使用，所以总共需要添加依赖的包有slf4j-api.jar，logback-core.jar，logback-classic.jar，logback-access.jar这个暂时用不到所以不添加依赖了，maven配置123456789101112131415161718192021222324 &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;logback.version&gt;1.1.7&lt;/logback.version&gt; &lt;slf4j.version&gt;1.7.21&lt;/slf4j.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2、logback.xml配置12345678910111213141516171819202122232425262728293031323334&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration debug=\"false\"&gt;&lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--&gt;&lt;property name=\"LOG_HOME\" value=\"/home\" /&gt;&lt;!-- 控制台输出 --&gt;&lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt;&lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt;&lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;&lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;&lt;/encoder&gt;&lt;/appender&gt;&lt;!-- 按照每天生成日志文件 --&gt;&lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt;&lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt;&lt;!--日志文件输出的文件名--&gt;&lt;FileNamePattern&gt;$&#123;LOG_HOME&#125;/TestWeb.log.%d&#123;yyyy-MM-dd&#125;.log&lt;/FileNamePattern&gt;&lt;!--日志文件保留天数--&gt;&lt;MaxHistory&gt;30&lt;/MaxHistory&gt;&lt;/rollingPolicy&gt;&lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt;&lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;&lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;&lt;/encoder&gt;&lt;!--日志文件最大的大小--&gt;&lt;triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt;&lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt;&lt;/triggeringPolicy&gt;&lt;/appender&gt;&lt;!-- 日志输出级别 --&gt;&lt;root level=\"INFO\"&gt;&lt;appender-ref ref=\"STDOUT\" /&gt;&lt;/root&gt;&lt;/configuration&gt; 3、java代码12345678910111213 /** * Hello world! */ public class App &#123; private final static Logger logger = LoggerFactory.getLogger(App.class); public static void main(String[] args) &#123; logger.info(\"logback 成功了\"); logger.error(\"logback 成功了\"); logger.debug(\"logback 成功了\"); &#125; &#125; 我的logback.xml常用配置：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration scan=\"true\" scanPeriod=\"60 seconds\"&gt;&lt;property name=\"LOG_HOME\" value=\"../log2\" /&gt; &lt;!-- Simple file output --&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- encoder defaults to ch.qos.logback.classic.encoder.PatternLayoutEncoder --&gt; &lt;encoder&gt; &lt;pattern&gt; [ %-5level] [%date&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;] %logger&#123;96&#125; [%line] [%thread]- %msg%n &lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- rollover daily 配置日志所生成的目录以及生成文件名的规则 --&gt; &lt;fileNamePattern&gt;$&#123;LOG_HOME&#125;/log_%d&#123;yyyyMMdd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;!-- or whenever the file size reaches 64 MB --&gt; &lt;maxFileSize&gt;64 MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;/filter&gt; &lt;!-- Safely log to the same file from multiple JVMs. Degrades performance! --&gt; &lt;prudent&gt;false&lt;/prudent&gt; &lt;/appender&gt; &lt;!-- Console output --&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;!-- encoder defaults to ch.qos.logback.classic.encoder.PatternLayoutEncoder --&gt; &lt;encoder&gt; &lt;pattern&gt; [ %-5level] [%date&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;] %logger&#123;96&#125; [%line] [%thread]- %msg%n &lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 此处设置字符集 --&gt; &lt;/encoder&gt; &lt;!-- Only log level WARN and above --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;!-- 邮件监控异常 --&gt;&lt;!-- &lt;appender name=\"EMAIL\" class=\"ch.qos.logback.classic.net.SMTPAppender\"&gt; &lt;smtpHost&gt;smtp.163.com&lt;/smtpHost&gt; &lt;username&gt;cairs-2w010@163.com&lt;/username&gt; &lt;password&gt;zxc1s2dsa46&lt;/password&gt; &lt;from&gt;cairs-2010@163.com&lt;/from&gt; &lt;to&gt;403411d876@qq.com&lt;/to&gt; &lt;subject&gt;【web-ext-Error】: %logger&lt;/subject&gt; &lt;layout class=\"ch.qos.logback.classic.html.HTMLLayout\"/&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;/filter&gt; &lt;/appender&gt;--&gt; &lt;!-- Enable FILE and STDOUT appenders for all log messages. By default, only log at level INFO and above. --&gt; &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"FILE\" /&gt; &lt;!--&lt;appender-ref ref=\"STDOUT\" /&gt;--&gt; &lt;!--&lt;appender-ref ref=\"EMAIL\" /&gt;--&gt; &lt;/root&gt; &lt;!-- For loggers in the these namespaces, log at all levels. --&gt; &lt;!-- &lt;logger name=\"pedestal\" level=\"ALL\" /&gt; &lt;logger name=\"hammock-cafe\" level=\"ALL\" /&gt; &lt;logger name=\"user\" level=\"ALL\" /&gt; --&gt;&lt;/configuration&gt;","categories":[{"name":"java框架","slug":"java框架","permalink":"https://reasoncai.github.io/categories/java框架/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://reasoncai.github.io/tags/日志/"}]},{"title":"redis-cluster搭建（3主3从）","slug":"redis-cluster搭建（3主3从）","date":"2017-04-25T06:14:45.000Z","updated":"2017-05-06T06:11:10.000Z","comments":true,"path":"2017/04/25/redis-cluster搭建（3主3从）/","link":"","permalink":"https://reasoncai.github.io/2017/04/25/redis-cluster搭建（3主3从）/","excerpt":"一、搭建环境 os:centos6.4 redis:3.0.5","text":"一、搭建环境 os:centos6.4 redis:3.0.5 二、搭建步骤1.安装必要的依赖 安装gcc：yum install gcc 安装rubygems：yum install rubygems 安装ruby的redis驱动：gem install redis 2..获取安装包使用下载好的包redis-3.0.5.tar.gz或直接命令下载：wget http://download.redis.io/releases/redis-3.0.5.tar.gz 将安装包放到/soft/目录下:mv redis-3.0.5.tar.gz /soft/ 3.安装编译 cd /soft tar zxvf redis-3.0.5.tar.gz cd redis-3.0.5 make MALLOC=libc make install PREFIX=/usr/local/redis 4.创建文件夹 mkdir /data/redis-cluster -p cd /data/redis-cluster/ mkdir 7000 7001 7002 7003 7004 7005 5.拷贝及修改配置文件 cp /soft/redis-3.0.5/redis.conf /data/redis-cluster/7000/ cp /soft/redis-3.0.5/redis.conf /data/redis-cluster/7001/ cp /soft/redis-3.0.5/redis.conf /data/redis-cluster/7002/ cp /soft/redis-3.0.5/redis.conf /data/redis-cluster/7003/ cp /soft/redis-3.0.5/redis.conf /data/redis-cluster/7004/ cp /soft/redis-3.0.5/redis.conf /data/redis-cluster/7005/ vim /data/redis-cluster/7000/redis.conf分别修改以上路径的配置文件内容项：7000-7005 1234567daemonize yespidfile /var/run/redis_7000.pidport 7000cluster-enabled yescluster-config-file nodes_7000.confcluster-node-timeout 15000appendonly yes 6.启动6个redis实例 /usr/local/redis/bin/redis-server /data/redis-cluster/7000/redis.conf /usr/local/redis/bin/redis-server /data/redis-cluster/7001/redis.conf /usr/local/redis/bin/redis-server /data/redis-cluster/7002/redis.conf /usr/local/redis/bin/redis-server /data/redis-cluster/7003/redis.conf /usr/local/redis/bin/redis-server /data/redis-cluster/7004/redis.conf /usr/local/redis/bin/redis-server /data/redis-cluster/7005/redis.conf 7.将集群管理程序复制到redis安装目录下cp /soft/redis-3.0.5/src/redis-trib.rb /usr/local/redis/bin/ 8.创建集群/usr/local/redis/bin/redis-trib.rb create –replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 使用create命令 --replicas 1 参数表示为每个主节点创建一个从节点，其他参数是实例的地址集合 创建成功： 9.检验测试9.1测试存取值 ​ 客户端连接集群redis-cli需要带上 -c ，redis-cli -c -p 端口号 ​ 发现在几个节点中跳来跳去。 9.2测试集群节点选举 查看集群目前状况：/usr/local/redis/bin/redis-cli -c -p 7000 cluster nodes 可以看出7000,7001,7002为master节点，7003,7004,7005为对应从节点 现在杀掉7001节点的进程，再看看集群状况： 可以看到，节点7001为fail状态，它的从节点7004被选举为master节点 现在我们将7001节点重新启动，看是否会自动加入集群中以及充当master节点还是slave节点。 可以看到7001节点恢复了，成为了7004节点的从节点。 三、附录redis配置参数说明 daemonize：如需要在后台运行，把该项的值改为yes pdifile：把pid文件放在/var/run/redis.pid，可以配置到其他地址 bind：指定redis只接收来自该IP的请求，如果不设置，那么将处理所有请求，在生产环节中最好设置该项 port：监听端口，默认为6379 timeout：设置客户端连接时的超时时间，单位为秒 loglevel：等级分为4级，debug，revbose，notice和warning。生产环境下一般开启notice logfile：配置log文件地址，默认使用标准输出，即打印在命令行终端的端口上 database：设置数据库的个数，默认使用的数据库是0 save：设置redis进行数据库镜像的频率 rdbcompression：在进行镜像备份时，是否进行压缩 dbfilename：镜像备份文件的文件名 dir：数据库镜像备份的文件放置的路径 slaveof：设置该数据库为其他数据库的从数据库 masterauth：当主数据库连接需要密码验证时，在这里设定 requirepass：设置客户端连接后进行任何其他指定前需要使用的密码 maxclients：限制同时连接的客户端数量 maxmemory：设置redis能够使用的最大内存 appendonly：开启appendonly模式后，redis会把每一次所接收到的写操作都追加到appendonly.aof文件中，当redis重新启动时，会从该文件恢复出之前的状态 appendfsync：设置appendonly.aof文件进行同步的频率 vm_enabled：是否开启虚拟内存支持 vm_swap_file：设置虚拟内存的交换文件的路径 vm_max_momery：设置开启虚拟内存后，redis将使用的最大物理内存的大小，默认为0 vm_page_size：设置虚拟内存页的大小 vm_pages：设置交换文件的总的page数量 vm_max_thrrads：设置vm IO同时使用的线程数量","categories":[{"name":"中间件","slug":"中间件","permalink":"https://reasoncai.github.io/categories/中间件/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://reasoncai.github.io/tags/redis/"}]}]}